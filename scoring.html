<!DOCTYPE HTML>
<!--
	Read Only by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Adrien Ehrhardt - Inria, CA CF</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main.css" />
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
		<link rel="icon" type="image/png" href="images/favicon.png" />
	</head>
	<body>

		<!-- Header -->
			<section id="header">
				<header>
					<span class="image avatar"><img src="images/avatar.jpg" alt="" /></span>
					<h1 id="logo"><a>Adrien Ehrhardt</a></h1>
                    <p>AI Assistant Professor @Polytechnique<br />
                    PhD @Lille University & @Inria<br />
                    in Machine Learning applied to Finance<br />
                    Data Scientist @Cr√©dit Agricole Consumer Finance</p>
				</header>
				<nav id="nav">
					<ul>
					        <li><a href="index.html">Home</a></li>
						<li><a href="cifre.html">Informations CIFRE</a></li>
						<li><a href="scoring.html" class="active">Introduction au Credit Scoring</a></li>
						<li><a href="rejectinference.html">Reject Inference</a></li>                                                
                        <li><a href="discretization.html">Discretization</a></li>
                        <li><a href="interaction_screening.html">Interaction screening</a></li>
                        <li><a href="logistic_trees.html">Logistic regression trees</a></li>
                        <li><a href="teaching.html">Teaching</a></li>
					</ul>
				</nav>
				<footer>
					<ul class="icons">
						<!--<li><a href="https://www.linkedin.com/in/adrien-ehrhardt" class="icon fa-linkedin"><span class="label">Linked-In</span></a></li>-->
						<!--<li><a href="#" class="icon fa-twitter"><span class="label">Twitter</span></a></li>-->
						<li><a href="https://www.facebook.com/adrien.ehrhardt.9" class="icon fa-facebook"><span class="label">Facebook</span></a></li>
						<li><a href="https://scholar.google.fr/citations?hl=fr&user=ISAbU0cAAAAJ&view_op=list_works" class="icon fa-google"><span class="label">Google</span></a></li>
						<li><a href="https://www.github.com/adimajo/" class="icon fa-github"><span class="label">Github</span></a></li>
						<li><a href="mailto:adrien.ehrhardt@centraliens-lille.org" class="icon fa-envelope"><span class="label">Email</span></a></li>
					</ul>
				</footer>
			</section>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">

						<!-- One -->
							<section id="one">
								<div class="container">
									<header class="major">
										<h2 id="chap1">Introduction au Credit Scoring</h2>
                                        </header>
                                        <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
                                        <p>N.B.: ce post s‚Äôinspire librement de mon premier chapitre de th√®se.</p>
                                        <p>Ce post est destin√© √† poser les bases de l‚Äôapprentissage statistique dans le cadre des cr√©dits √† la consommation. On introduira dans une premi√®re partie la terminologie consacr√©e du cr√©dit √† la consommation avant de s‚Äôattarder plus en d√©tails, dans une seconde partie, sur l‚Äô√©tat de l‚Äôart industriel du <em>Credit Scoring</em> √† travers une √©tude bibliographique et la pratique des institutions financi√®res dont <span data-acronym-label="cacf" data-acronym-form="singular+short">CACF</span>. On clot√ªrera le post par une troisi√®me partie : les maths qui justifient les pratiques d√©crites dans les deux premi√®res parties.</p>
                                        <h2 id="chap1:sec1">Le march√© du cr√©dit √† la consommation : quels enjeux ?</h2>
                                        <h3 id="quest-ce-quun-cr√©dit-√†-la-consommation">Qu‚Äôest-ce qu‚Äôun cr√©dit √† la consommation ?</h3>
                                        <p>En pratique, on peut distinguer majoritairement trois produits de cr√©dit √† la consommation.</p>
                                        <p>Le premier d‚Äôentre eux, le cr√©dit classique, est le produit historique. De la m√™me mani√®re qu‚Äôun cr√©dit immobilier, le client emprunte une somme fixe qui lui est attribu√©e au moment du financement et qu‚Äôil rembourse selon un √©ch√©ancier d√©fini √† l‚Äôavance (taux et nombre de mensualit√©s fixes). D‚Äôun point de vue statistique, le traitement est relativement simple : que ce soit √† l‚Äôoctroi, pour d√©terminer le risque du client, ou au cours de la vie du dossier, pour provisionner les pertes potentielles, tout est connu √† l‚Äôavance. Il suffit en quelque sorte de v√©rifier le paiement de la mensualit√© √† la date pr√©vue. Il convient √©galement de pr√©ciser que certains cr√©dits classiques sont dits affect√©s, c‚Äôest-√†-dire qu‚Äôils financent un bien pr√©cis et identifi√©, de sorte que le pr√™t transite directement de l‚Äôorganisme pr√™teur au vendeur (un concessionnaire par exemple). Par ailleurs, la mise en d√©faut du cr√©dit entra√Æne g√©n√©ralement une proc√©dure de recouvrement de la dette qui peut se solder, dans le cas d‚Äôun cr√©dit affect√©, par la r√©cup√©ration du bien par un huissier. L√† encore, d‚Äôun point de vue statistique, il para√Æt indispensable de consigner les caract√©ristiques du bien sous-jacent afin d‚Äôint√©grer sa valeur r√©siduelle r√©cup√©rable en cas de d√©faut.</p>
                                        <p>Le second produit, d√©velopp√© √† partir de 1965 en France et ayant connu une forte croissance depuis¬†<a href="#ducourant2009credit" class="citation" data-cites="ducourant2009credit">[25]</a> mais n√©anmoins bien moins r√©pandu en Europe qu‚Äôaux Etats-Unis par exemple¬†<a href="#credit_cards_country" class="citation" data-cites="credit_cards_country">[26]</a>, est le cr√©dit renouvelable. Un capital dit accord√© ou autoris√© est attribu√© au demandeur qui peut utiliser tout ou partie de ce montant et le rembourse √† un taux et par mensualit√©s d√©pendants tous deux de la proportion du capital consomm√©. Au fur et √† mesure du remboursement du capital emprunt√©, le capital ‚Äúempruntable‚Äù, c‚Äôest-√†-dire la diff√©rence entre le capital accord√© et le capital emprunt√© √† date, se reconstitue et de nouvelles utilisations sont possibles, toujours dans la limite du capital accord√© au d√©part. D‚Äôun point de vue statistique √† nouveau, plusieurs probl√®mes se posent du fait du caract√®re intrins√®quement al√©atoire de l‚Äôutilisation ou non de tout ou partie de la ligne de cr√©dit accord√©e. Plus pr√©cis√©ment, ce produit pr√©sente un risque important port√© par deux facteurs : premi√®rement, le taux √©lev√© attire des clients risqu√©s, au taux de d√©faut plus √©lev√© que pour un cr√©dit classique par exemple ; deuxi√®mement, ces cr√©dits portent un risque dit de hors-bilan tr√®s fort, puisqu‚Äô√† tout moment, l‚Äôensemble des cr√©dits accord√©s mais non utilis√©s et donc non comptabilis√©s ‚Äúau bilan‚Äù, c‚Äôest-√†-dire comme une dette du client envers l‚Äô√©tablissement bancaire, peuvent √™tre utilis√©s et faire d√©faut. La mauvaise quantification de ce risque est √† pr√©sent reconnu comme un important catalyseur de la r√©cente crise financi√®re<a href="#karim2013off" class="citation" data-cites="karim2013off">[29]</a>.</p>
                                        <p>Enfin, la <span data-acronym-label="location" data-acronym-form="singular+short">location</span> a r√©cemment connu un essor important¬†<a href="#peden_2018" class="citation" data-cites="peden_2018">[28]</a>. D‚Äôabord concentr√©e sur le secteur automobile, elle se d√©veloppe actuellement pour les produits √©lectroniques (smartphones notamment) et m√™me plus r√©cemment pour des produits plus insolites comme les matelas¬†<a href="#dicharry_2017" class="citation" data-cites="dicharry_2017">[27]</a>. Comme le <span data-acronym-label="creditaffecte" data-acronym-form="singular+short">cr√©dit affect√©</span>, il est important de prendre en compte les donn√©es du bien lou√© afin d‚Äô√©valuer le risque que porte ce produit, la difficult√© suppl√©mentaire reposant sur l‚Äô√©ventualit√© de l‚Äôexercice de l‚Äôhypoth√©tique option d‚Äôachat.</p>
                                        <p>De cette partie, deux consid√©rations statistiques doivent retenir notre attention : d‚Äôabord, ces diff√©rents produits n√©cessitent des traitements diff√©rents dans la mesure o√π leur risque est intrins√®quement diff√©rent ; ensuite, les donn√©es disponibles pour chacun de ces produits diff√®rent : par exemple, les donn√©es du produit financ√© ne sont disponibles que pour les cr√©dits affect√©s et les <span data-acronym-label="location" data-acronym-form="plural+short">locations</span>.</p>
                                        <h3 id="cr√©dit-agricole-consumer-finance">Cr√©dit Agricole Consumer Finance (CACF)</h3>
                                        <p><span data-acronym-label="cacf" data-acronym-form="singular+short">CACF</span> op√®re dans de nombreux pays. En France, c‚Äôest principalement √† travers la marque Sofinco que sont commercialis√©s les cr√©dits √† la consommation pour lesquels il existe une relation directe entre <span data-acronym-label="cacf" data-acronym-form="singular+short">CACF</span> et le client (dite B2C), par exemple lorsqu‚Äôun demandeur se rend directement sur le site internet <a href="https://www.sofinco.fr">sofinco.fr</a>.</p>
                                        <p>Par ailleurs, de nombreux cr√©dits √† la consommation sont distribu√©s √† travers un r√©seau de partenaires, qui jouent le r√¥le d‚Äôinterm√©diaires (on parle alors de B2B) : concessionnaires automobile, distributeurs d‚Äô√©lectrom√©nager, etc.</p>
                                        <p>Enfin, <span data-acronym-label="cacf" data-acronym-form="singular+short">CACF</span> faisant partie du groupe Cr√©dit Agricole, de nombreuses agences bancaires distribuent des cr√©dits √† la consommation √† leur client√®le bancaris√©, par l‚Äôinterm√©diaire des gestionnaires de compte.</p>
                                        <p>L√† encore, on constate que les sp√©cificit√©s des canaux de distribution des cr√©dits impactent grandement la collecte des donn√©es et leur traitement statistique. En effet, les informations collect√©es sur le client, le produit et √©ventuellement l‚Äôapporteur d‚Äôaffaires sont diff√©rentes selon le canal.</p>
                                        <p>Dans la partie suivante, la m√©thodologie pr√©sent√©e est sp√©cifique √† <span data-acronym-label="cacf" data-acronym-form="singular+short">CACF</span> ; il pourra n√©anmoins √™tre admis que, dans les grandes lignes, cette m√©thodologie est similaire √† la concurrence d‚Äôune part, et √† la pratique d‚Äôautres pays (europ√©ens du moins) puisque la l√©gislation sur la protection et le traitement des donn√©es est sensiblement similaire (du fait de l‚Äôentr√©e en vigueur r√©cente de la GDPR) et le fait que les √©tablissements bancaires poss√®dent g√©n√©ralement des filiales dans plusieurs pays d‚ÄôEurope et y font appliquer la m√™me m√©thodologie.</p>
                                        <h2 id="chap1:sec2">Le <em>Credit Scoring</em> : √©tat de l‚Äôart de la pratique industrielle</h2>
                                        <h3 id="collecte-des-donn√©es">Collecte des donn√©es</h3>
                                        <p>La partie pr√©c√©dente a mis en exergue la pluralit√© des sources de donn√©es¬†: Cr√©dit Agricole, √† travers sa filiale d√©di√©e aux cr√©dits √† la consommation Cr√©dit Agricole Consumer Finance, finance des cr√©dits en France √† travers sa marque Sofinco (B2C), ou en magasins / concessions chez des partenaires (B2B) o√π les donn√©es du demandeur de cr√©dit sont collect√©es. La figure¬†<a href="#fig:souscription" data-reference-type="ref" data-reference="fig:souscription">[1]</a> pr√©sente par exemple le formulaire de souscription en vigueur pour un cr√©dit automobile aupr√®s de Sofinco <em>via</em> son site web. Dans cet exemple, des donn√©es socio-d√©mographiques et du v√©hicule √† financer sont demand√©es. Pour un client, elles sont not√©es <span class="math inline">\(\boldsymbol{x} = (x_j)_1^d\)</span> dans la suite (on reviendra de mani√®re plus formelle sur l‚Äôensemble des notations introduites pour les besoins du cas d‚Äôapplication en fin de chapitre). Ces informations sont de nature continue, c‚Äôest-√†-dire <span class="math inline">\(x_j \in \mathbb{R}\(</span>, ou cat√©gorielle, c‚Äôest-√†-dire que l‚Äôon se donne, √† titre d‚Äôexemple, un encodage ‚ÄúM√©tier = technicien‚Äù <span class="math inline">\(\rightarrow x_j = 1\)</span>, ‚ÄúM√©tier = ouvrier‚Äù <span class="math inline">\(\rightarrow x_j = 2\)</span>, ‚Ä¶de telle sorte que l‚Äôon consid√®re que <span class="math inline">\(x_j \in \mathbb{N}_{o_j} = \{1, \dots,l_j\}\)</span>, o√π <span class="math inline">\(l_j\)</span> repr√©sente le nombre de modalit√©s de <span class="math inline"><em>x</em><sub><em>j</em></sub></span> et sans notion d‚Äôordre.</p>
<!--                                        <figure>-->
<!--                                            <img src="figures/chapitre1/casa.png" alt="Sch√©ma des interactions entre les entreprises / marques et la collecte de demandes de cr√©dits." id="fig:marque" style="width:2cm" /><figcaption>Sch√©ma des interactions entre les entreprises / marques et la collecte de demandes de cr√©dits.<span label="fig:marque"></span></figcaption>-->
<!--                                        </figure>-->
<!--                                        -->
<!--                                        -->
<!--                                        <figure>-->
<!--                                            <img src="figures/chapitre1/logo.png" alt="Sch√©ma des interactions entre les entreprises / marques et la collecte de demandes de cr√©dits." id="fig:marque" style="width:5cm" /><figcaption>Sch√©ma des interactions entre les entreprises / marques et la collecte de demandes de cr√©dits.<span label="fig:marque"></span></figcaption>-->
<!--                                        </figure>-->

                                        
                                        
<!--                                        <p><img src="figures/chapitre1/sofinco.png" title="fig:" alt="Sch√©ma des interactions entre les entreprises / marques et la collecte de demandes de cr√©dits." id="fig:marque" style="width:3.5cm" /> <img src="figures/chapitre1/client.png" title="fig:" alt="Sch√©ma des interactions entre les entreprises / marques et la collecte de demandes de cr√©dits." id="fig:marque" style="width:1.1cm" /></p>-->
<!--                                        <p><span>4</span></p>-->
<!--                                        <figure>-->
<!--                                            <img src="figures/chapitre1/orchestra.jpg" alt="Sch√©ma des interactions entre les entreprises / marques et la collecte de demandes de cr√©dits." id="fig:marque" style="width:2cm" /><figcaption>Sch√©ma des interactions entre les entreprises / marques et la collecte de demandes de cr√©dits.<span label="fig:marque"></span></figcaption>-->
<!--                                        </figure>-->
<!--                                        -->
<!--                                        <figure>-->
<!--                                            <img src="figures/chapitre1/darty.png" alt="Sch√©ma des interactions entre les entreprises / marques et la collecte de demandes de cr√©dits." id="fig:marque" style="width:1cm" /><figcaption>Sch√©ma des interactions entre les entreprises / marques et la collecte de demandes de cr√©dits.<span label="fig:marque"></span></figcaption>-->
<!--                                        </figure>-->
<!--                                        -->
<!--                                        <figure>-->
<!--                                            <img src="figures/chapitre1/redoute.png" alt="Sch√©ma des interactions entre les entreprises / marques et la collecte de demandes de cr√©dits." id="fig:marque" style="width:1.5cm" /><figcaption>Sch√©ma des interactions entre les entreprises / marques et la collecte de demandes de cr√©dits.<span label="fig:marque"></span></figcaption>-->
<!--                                        </figure>-->
<!--                                        -->
<!--                                        <p><img src="figures/chapitre1/fnac.png" title="fig:" alt="Sch√©ma des interactions entre les entreprises / marques et la collecte de demandes de cr√©dits." id="fig:marque" style="width:1cm" /> <img src="figures/chapitre1/client.png" title="fig:" alt="Sch√©ma des interactions entre les entreprises / marques et la collecte de demandes de cr√©dits." id="fig:marque" style="width:1.1cm" /></p>-->
                                        <figure>
                                            <img src="figures/chapitre1/souscription.png" alt="[1] Formulaire de souscription d‚Äôun cr√©dit automobile Sofinco." style="width:15cm" /><figcaption><span id="fig:souscription" label="fig:souscription">[1]</span> Formulaire de souscription d‚Äôun cr√©dit automobile Sofinco.</figcaption>
                                        </figure>
                                        <p>On consid√®re que ces caract√©ristiques sont une r√©alisation du vecteur al√©atoire de design <span class="math inline">\(\boldsymbol{x} = (X_j)_1^d \in \mathcal{X}\)</span> sur un espace probabilis√© <span class="math inline">(<em>Œ©</em>,‚ÄÜùíú,‚ÄÜ‚Ñô)</span>, que l‚Äôon observe sur l‚Äôensemble des <span class="math inline"><em>n</em></span> demandeurs de cr√©dit √† la consommation pour former, dans la litt√©rature consacr√©e au <em>machine learning</em>, la matrice de design <span class="math inline">\(\boldsymbol{\mathbf{x}} = (x_{i,j})_{1 \leq i \leq n, 1 \leq j \leq d}\)</span>.</p>
                                        <p>A ce stade, deux remarques importantes doivent √™tre faites : d‚Äôabord, une partie de ces caract√©ristiques peut √™tre absente. Par ailleurs, elles sont √† ce stade d√©claratives (des contr√¥les suppl√©mentaires peuvent avoir lieu en fonction du montant demand√© par exemple), et donc associ√©es √† un degr√© de certitude variable, la tentation √©tant grande, afin de s‚Äôassurer de l‚Äôattribution du cr√©dit, de d√©former la r√©alit√© de ses charges, ses revenus, etc. En synth√®se, le tableau¬†<a href="#tab:design" data-reference-type="ref" data-reference="tab:design">[1]</a> pr√©sente un exemple simplifi√© de matrice de design en <em>Credit Scoring</em>. En pratique un tel tableau structur√© est directement mis √† disposition des statisticiens de <span data-acronym-label="cacf" data-acronym-form="singular+short">CACF</span> √† travers le logiciel de traitement statistique SAS.</p>
                                        
                                        <table>
                                            <caption><span id="tab:design" label="tab:design">[1]</span> Exemple simplifi√© de caract√©ristiques de demandeurs de cr√©dit : pr√©sence de valeurs manquantes ou extr√™mes.</caption>
                                            <thead>
                                                <tr class="header">
                                                    <th style="text-align: left;">Travail</th>
                                                    <th style="text-align: left;">Logement</th>
                                                    <th style="text-align: left;">Dur√©e d‚Äôemploi</th>
                                                    <th style="text-align: left;">Enfants</th>
                                                    <th style="text-align: left;">Statut familial</th>
                                                    <th style="text-align: left;">Salaire</th>
                                                </tr>
                                            </thead>
                                            <tbody>
                                                <tr class="odd">
                                                    <td style="text-align: left;">Ouvrier qualifi√©</td>
                                                    <td style="text-align: left;">Propri√©taire</td>
                                                    <td style="text-align: left;">20</td>
                                                    <td style="text-align: left;">3</td>
                                                    <td style="text-align: left;">Veuf</td>
                                                    <td style="text-align: left;">30 000</td>
                                                </tr>
                                                <tr class="even">
                                                    <td style="text-align: left;">Technicien</td>
                                                    <td style="text-align: left;">En location</td>
                                                    <td style="text-align: left;">Manquant</td>
                                                    <td style="text-align: left;">1</td>
                                                    <td style="text-align: left;">Concubinage</td>
                                                    <td style="text-align: left;"><span>1700</span></td>
                                                </tr>
                                                <tr class="odd">
                                                    <td style="text-align: left;">Technicien sp√©cialis√©</td>
                                                    <td style="text-align: left;">Acc√©dant</td>
                                                    <td style="text-align: left;">5</td>
                                                    <td style="text-align: left;">0</td>
                                                    <td style="text-align: left;">Divorc√©</td>
                                                    <td style="text-align: left;"><span>4000</span></td>
                                                </tr>
                                                <tr class="even">
                                                    <td style="text-align: left;">Cadre</td>
                                                    <td style="text-align: left;">Par l‚Äôemployeur</td>
                                                    <td style="text-align: left;">8</td>
                                                    <td style="text-align: left;">2</td>
                                                    <td style="text-align: left;">C√©libataire</td>
                                                    <td style="text-align: left;"><span>2700</span></td>
                                                </tr>
                                                <tr class="odd">
                                                    <td style="text-align: left;">Employ√©</td>
                                                    <td style="text-align: left;">En location</td>
                                                    <td style="text-align: left;">12</td>
                                                    <td style="text-align: left;">2</td>
                                                    <td style="text-align: left;">Mari√©</td>
                                                    <td style="text-align: left;"><span>1400</span></td>
                                                </tr>
                                                <tr class="even">
                                                    <td style="text-align: left;">Ouvrier</td>
                                                    <td style="text-align: left;">Par la famille</td>
                                                    <td style="text-align: left;">2</td>
                                                    <td style="text-align: left;">0</td>
                                                    <td style="text-align: left;">C√©libataire</td>
                                                    <td style="text-align: left;"><span>1200</span></td>
                                                </tr>
                                            </tbody>
                                        </table>
                                        <h3 id="subsec:segmentation">Pr√©paration des donn√©es et segmentation</h3>
                                        <p>Le tableau¬†<a href="#tab:design" data-reference-type="ref" data-reference="tab:design">[1]</a> fait appara√Ætre deux probl√®mes bien connus en statistique : la gestion des observations manquantes et celle des valeurs extr√™mes (<em>outliers</em>).</p>
                                        <p>Concernant les observations manquantes, deux strat√©gies diff√©rentes peuvent √™tre employ√©es. <span data-acronym-label="cacf" data-acronym-form="singular+short">CACF</span> r√©alise une ‚Äúsegmentation‚Äù de sa client√®le, de sorte que, √† titre d‚Äôexemple, plusieurs mod√®les statistiques sp√©cialis√©s √† un sous-ensemble de la population totale peuvent √™tre employ√©s, chacun d‚Äôeux b√©n√©ficiant alors de donn√©es compl√®tes. Le processus de choix des ‚Äúsegments‚Äù, <em>i.e.</em>¬†la partition des lignes de <span class="math inline">\(\boldsymbol{\mathbf{x}}\)</span> sur lesquels d√©velopper des mod√®les s√©par√©s, est bas√© soit sur l‚Äôhistoire de l‚Äôentreprise (par exemple, un mod√®le sp√©cifique aux cr√©dits automobiles a pu √™tre d√©velopp√© au d√©but de la commercialisation de ce produit), soit sur des heuristiques tr√®s simples.</p>
                                        <p>L‚Äôautre pr√©-traitement r√©pandu dans le milieu du <em>Credit Scoring</em> pour faire face aux donn√©es manquantes et aux valeurs extr√™mes est la discr√©tisation (pour les variables continues uniquement). Cela consiste √† transformer une variable continue dont certaines observations sont manquantes en une variable cat√©gorielle dont chaque modalit√© correspond √† un intervalle de la variable continue d‚Äôorigine et / ou au fait que l‚Äôobservation d‚Äôorigine √©tait manquante. Un exemple de discr√©tisation de la variable ‚Äú√Çge du client‚Äù est visible en figure¬†<a href="#tab:disc_ex" data-reference-type="ref" data-reference="tab:disc_ex">[2]</a> ; ainsi, le fait que l‚Äôobservation soit manquante est consid√©r√©e comme une information √† part enti√®re et les valeurs extr√™mes sont regroup√©es dans le dernier intervalle.</p>
                                        
                                        <table>
                                            <caption><span id="tab:disc_ex" label="tab:disc_ex">[2]</span> Exemple de variable continue discr√©tis√©e.</caption>
                                            <thead>
                                                <tr class="header">
                                                    <th style="text-align: left;">√Çge du client</th>
                                                    <th style="text-align: left;">18</th>
                                                    <th style="text-align: left;">Manquant</th>
                                                    <th style="text-align: left;">47</th>
                                                    <th style="text-align: left;">25</th>
                                                    <th style="text-align: left;">35</th>
                                                    <th style="text-align: left;">61</th>
                                                </tr>
                                            </thead>
                                            <tbody>
                                                <tr class="odd">
                                                    <td style="text-align: left;">√Çge discr√©tis√©</td>
                                                    <td style="text-align: left;">18-30 &amp; Manquant</td>
                                                    <td style="text-align: left;">18-30 &amp; Manquant</td>
                                                    <td style="text-align: left;">45-<span class="math inline">‚àû</span></td>
                                                    <td style="text-align: left;">18-30</td>
                                                    <td style="text-align: left;">30-45</td>
                                                    <td style="text-align: left;">45-<span class="math inline">‚àû</span></td>
                                                </tr>
                                            </tbody>
                                        </table>
                                        <p>√Ä pr√©sent, on dispose de donn√©es rendues compl√®tes sur l‚Äôensemble des demandeurs de cr√©dit et l‚Äôon souhaite pr√©dire le niveau de risque pr√©sent√© par un nouveau demandeur. Il convient donc dans un premier temps de quantifier le risque de chaque √©chantillon de la matrice de design <span class="math inline">\(\boldsymbol{\mathbf{x}}\)</span>.</p>
                                        <h3 id="subsec:critere">D√©finir les ‚Äúbons‚Äù et ‚Äúmauvais‚Äù payeurs</h3>
                                        <p>L‚Äôinstitut financier emprunte de l‚Äôargent sur les march√©s √† un taux relativement faible et le redistribue aux demandeurs de cr√©dit qu‚Äôil juge profitables, c‚Äôest-√†-dire susceptible de rembourser cette dette. Il y a donc un syst√®me d‚Äôacceptation, reposant sur un ensemble de r√®gles automatiques et potentiellement une √©tude humaine. On consid√®re que le m√©canisme qui conduit au financement <em>in fine</em> de la demande de cr√©dit est al√©atoire, not√© <span class="math inline"><em>Z</em></span> et prenant les valeurs f (pour les clients dont la demande est financ√©e) et nf (pour les non-financ√©s).</p>
                                        <p>Il convient de noter ici que les diff√©rents processus qui conduisent √† un non financement du dossier sont tr√®s nombreux : interruption / r√©tractation du demandeur, refus automatique (endettement, <span data-acronym-label="score" data-acronym-form="singular+short">score</span> existant, ‚Ä¶) ou refus d‚Äôun conseiller client√®le.</p>
                                        <p>En essence, il est souhaitable de mesurer la profitabilit√© de chaque cr√©dit, par exemple en actualisant les remboursements et les pertes g√©n√©r√©s par chaque client √† la date de d√©blocage des fonds, et en d√©duisant l‚Äôensemble des co√ªts (financement, traitement, recouvrement, ‚Ä¶). En pratique, peu d‚Äôinstitutions proc√®dent ainsi malgr√© quelques travaux r√©cents¬†<a href="#finlay2010credit" class="citation" data-cites="finlay2010credit">[21]</a>. Par ailleurs, les caract√©ristiques du client sont elles-m√™mes √©volutives¬†: les informations collect√©es √† <span class="math inline"><em>t</em>‚ÄÑ=‚ÄÑ0</span> au moment de la demande peuvent avoir chang√© au moment du financement du bien √† <span class="math inline"><em>t</em>‚ÄÑ=‚ÄÑfin</span> (qui peut intervenir plusieurs mois apr√®s pour un v√©hicule sur commande par exemple), tout comme les moments de vie ult√©rieurs √©ventuels comme les divorces, les pertes d‚Äôemploi, ‚Ä¶qui ne peuvent √™tre collect√©es ult√©rieurement par les organismes financiers, comme sch√©matis√© sur la figure¬†<a href="#fig:moments" data-reference-type="ref" data-reference="fig:moments">[2]</a>.</p>
                                        <p>En cons√©quence, on s√©lectionne g√©n√©ralement 12 mois de dossiers de demandes de cr√©dit pour s‚Äôaffranchir de ph√©nom√®nes de saisonnalit√© et on observe le mois suivant la date de financement de chaque dossier si la mensualit√© a √©t√© rembours√©e. On r√©p√®te le processus jusqu‚Äô√† un horizon de 12 √† 24 mois selon la disponibilit√© des donn√©es. On dispose alors pour chaque client d‚Äôune s√©rie temporelle qui indique si le remboursement mensuel a √©t√© effectu√© ou non. On cherche ensuite √† se ramener √† une seule variable al√©atoire cible <span class="math inline">\(Y \in \{0,1\}\)</span> qualifiant un client ‚Äúbon‚Äù par <span class="math inline"><em>Y</em>‚ÄÑ=‚ÄÑ1</span> ou ‚Äúmauvais‚Äù par <span class="math inline"><em>Y</em>‚ÄÑ=‚ÄÑ0</span>. L‚Äôheuristique actuellement utilis√©e est la suivante :</p>
                                        <ul>
                                            <li><p>Pour un ensemble d‚Äôhorizons <span class="math inline"><em>T</em>‚ÄÑ‚àà‚ÄÑ{6,‚ÄÜ12,‚ÄÜ18,‚ÄÜ24}</span> mois et d‚Äôimpay√©s cons√©cutifs <span class="math inline"><em>I</em>‚ÄÑ‚àà‚ÄÑ{1,‚ÄÜ‚Ä¶,‚ÄÜ4}</span> ,</p>
                                                <ul>
                                                    <li><p>Tracer le graphique d‚Äô‚Äúhorizon du risque‚Äù : la proportion de clients ayant <span class="math inline"><em>I</em></span> impay√©s cons√©cutifs <span class="math inline"><em>T</em></span> mois apr√®s leur financement, dont un exemple est donn√© en figure¬†<a href="#fig:courbe_horizon" data-reference-type="ref" data-reference="fig:courbe_horizon">[3]</a> pour <span class="math inline"><em>I</em>‚ÄÑ=‚ÄÑ2</span>.</p>
                                                        <p>On cherche un point d‚Äôinflexion sur cette courbe, qui traduirait le fait qu‚Äôau-del√† d‚Äôun certain horizon <span class="math inline"><em>T</em></span>, la proportion de dossiers ‚Äúmauvais‚Äù n‚Äô√©volue plus et l‚Äôon consid√®re que tous les ‚Äúmauvais‚Äù clients sont d√©j√† identifi√©s.</p></li>
                                                    <li><p>Construire le tableau des <em>Roll Rates</em>, dont un exemple est donn√© en tableau¬†<a href="#tab:impayes" data-reference-type="ref" data-reference="tab:impayes">[3]</a> pour <span class="math inline"><em>T</em>‚ÄÑ=‚ÄÑ12</span>.</p>
                                                        <p>On cherche le nombre d‚Äôimpay√©s cons√©cutifs <span class="math inline"><em>I</em></span> au-del√† duquel la proportion de dossiers se d√©gradant (et donc fortement susceptibles de g√©n√©rer des pertes) est ‚Äúimportante‚Äù, g√©n√©ralement au-del√† de 50 %.</p></li>
                                                </ul></li>
                                            <li><p>Choisir le couple <span class="math inline">(<em>T</em>,‚ÄÜ<em>I</em>)</span> qui r√©pond au mieux aux crit√®res ci-dessus et permet d‚Äôavoir un nombre significatif de dossiers ‚Äúmauvais‚Äù. Il faut garder √† l‚Äôesprit que plus l‚Äôon choisit un horizon <span class="math inline"><em>T</em></span> faible et / ou un nombre √©lev√© d‚Äôimpay√©s cons√©cutifs <span class="math inline"><em>I</em></span>, plus la proportion <span class="math inline"><em>œÄÃÇ</em><sub>0</sub></span> (l‚Äôestimateur de la moyenne pour <span class="math inline"><em>œÄ</em><sub><em>i</em></sub>‚ÄÑ=‚ÄÑ<em>p</em>(<em>Y</em>‚ÄÑ=‚ÄÑ<em>i</em>)</span>) de dossiers ‚Äúmauvais‚Äù par rapport aux dossiers ‚Äúbons‚Äù devient faible. Or, on veut √©viter au maximum les nombreux probl√®mes que g√©n√®rent des classes d√©s√©quilibr√©es en classification supervis√©e¬†<a href="#sun2009classification" class="citation" data-cites="sun2009classification">[16]</a>.</p></li>
                                        </ul>
                                        
                                        <figure>
                                            <img src="figures/chapitre1/courbe_risque2.png" alt="[fig:courbe_horizon] Exemple de courbe d‚Äôhorizon risque : proportion de ‚Äúmauvais‚Äù clients (2 impay√©s cons√©cutifs) en fonction du nombre de mensualit√©s observ√©es." style="width:10cm" /><figcaption><span id="fig:courbe_horizon" label="fig:courbe_horizon">[3]</span> Exemple de courbe d‚Äôhorizon risque : proportion de ‚Äúmauvais‚Äù clients (2 impay√©s cons√©cutifs) en fonction du nombre de mensualit√©s observ√©es.</figcaption>
                                        </figure>
                                        
                                        <table>
                                            <caption><span id="tab:impayes" label="tab:impayes">[3]</span> Exemple d‚Äô√©volution de dossiers √† diff√©rents niveaux d‚Äôimpay√©s.</caption>
                                            <thead>
                                                <tr class="header">
                                                    <th style="text-align: left;">Impay√©s cons√©cutifs</th>
                                                    <th style="text-align: left;">Am√©lioration</th>
                                                    <th style="text-align: left;">Stabilit√©</th>
                                                    <th style="text-align: left;">D√©gradation</th>
                                                </tr>
                                            </thead>
                                            <tbody>
                                                <tr class="odd">
                                                    <td style="text-align: left;">0</td>
                                                    <td style="text-align: left;">0 %</td>
                                                    <td style="text-align: left;">95 %</td>
                                                    <td style="text-align: left;">5 %</td>
                                                </tr>
                                                <tr class="even">
                                                    <td style="text-align: left;">1</td>
                                                    <td style="text-align: left;">60 %</td>
                                                    <td style="text-align: left;">10 %</td>
                                                    <td style="text-align: left;">30 %</td>
                                                </tr>
                                                <tr class="odd">
                                                    <td style="text-align: left;">2</td>
                                                    <td style="text-align: left;">10%</td>
                                                    <td style="text-align: left;">30 %</td>
                                                    <td style="text-align: left;"><span style="color: red">60 %</span></td>
                                                </tr>
                                                <tr class="even">
                                                    <td style="text-align: left;">3</td>
                                                    <td style="text-align: left;">5%</td>
                                                    <td style="text-align: left;">25 %</td>
                                                    <td style="text-align: left;"><span>70 %</span></td>
                                                </tr>
                                                <tr class="odd">
                                                    <td style="text-align: left;">4</td>
                                                    <td style="text-align: left;">5%</td>
                                                    <td style="text-align: left;">15 %</td>
                                                    <td style="text-align: left;"><span>80 %</span></td>
                                                </tr>
                                                <tr class="even">
                                                    <td style="text-align: left;">5</td>
                                                    <td style="text-align: left;">5%</td>
                                                    <td style="text-align: left;">5 %</td>
                                                    <td style="text-align: left;"><span>90 %</span></td>
                                                </tr>
                                            </tbody>
                                        </table>
                                        <p>Pour des raisons pratiques et historiques, on choisit g√©n√©ralement <span class="math inline"><em>T</em>‚ÄÑ=‚ÄÑ12</span> mois et <span class="math inline"><em>I</em>‚ÄÑ=‚ÄÑ2</span> impay√©s cons√©cutifs. On consid√®re donc comme ‚Äúmauvais‚Äù (<span class="math inline"><em>Y</em>‚ÄÑ=‚ÄÑ0</span>) les dossiers financ√©s ayant eu au moins 2 mensualit√©s impay√©es cons√©cutives dans les 12 mois qui ont suivi leur financement, comme ‚Äúbons‚Äù (<span class="math inline"><em>Y</em>‚ÄÑ=‚ÄÑ1</span>) les dossiers n‚Äôayant pas eu d‚Äôimpay√©s, comme ‚Äúind√©termin√©s‚Äù les dossiers ayant eu 1 impay√© qui sont exclus de la mod√©lisation, et on exclut √©galement tous les dossiers non financ√©s (<span class="math inline">\(Z=\text{nf}\)</span>). On a alors le vecteur de r√©ponses <span class="math inline">\(\boldsymbol{\mathbf{y}}\)</span> dont un exemple est donn√© en tableau¬†<a href="#tab:rep_ex" data-reference-type="ref" data-reference="tab:rep_ex">[4]</a>.</p>
                                        
                                        <table>
                                            <caption><span id="tab:rep_ex" label="tab:rep_ex">[4]</span> Exemple de vecteur <span class="math inline">\(\boldsymbol{\mathbf{y}}\)</span> de qualification du risque des clients.</caption>
                                            <thead>
                                                <tr class="header">
                                                    <th style="text-align: center;"><span class="math inline"><em>y</em></span></th>
                                                </tr>
                                            </thead>
                                            <tbody>
                                                <tr class="odd">
                                                    <td style="text-align: center;">1</td>
                                                </tr>
                                                <tr class="even">
                                                    <td style="text-align: center;">Manquant - Non-financ√©</td>
                                                </tr>
                                                <tr class="odd">
                                                    <td style="text-align: center;">0</td>
                                                </tr>
                                                <tr class="even">
                                                    <td style="text-align: center;">Manquant - Ind√©termin√©</td>
                                                </tr>
                                                <tr class="odd">
                                                    <td style="text-align: center;">0</td>
                                                </tr>
                                                <tr class="even">
                                                    <td style="text-align: center;">1</td>
                                                </tr>
                                            </tbody>
                                        </table>
                                        <p>On en conclut que la performance de remboursement n‚Äôest observable que pour les clients financ√©s non ind√©termin√©s, que l‚Äôon va assimiler dans la suite √† ceux pour lesquels <span class="math inline">\(Z=\text{f}\)</span>. Toujours est-il qu‚Äô√† pr√©sent, on dispose de donn√©es <span class="math inline">\((\boldsymbol{\mathbf{x}},\boldsymbol{\mathbf{y}})\)</span> compl√®tes gr√¢ce auxquelles on souhaite apprendre un <span data-acronym-label="score" data-acronym-form="singular+short">score</span> qualifiant la qualit√© des emprunteurs, et associ√© √† un cutoff produisant une fonction de classification binaire discernant, parmi les futurs demandeurs de cr√©dit, les ‚Äúbons‚Äù des ‚Äúmauvais‚Äù clients.</p>
                                        <h3 id="subsec:apprentissage">L‚Äôapprentissage d‚Äôun <span data-acronym-label="score" data-acronym-form="singular+short">score</span></h3>
                                        <p>Malgr√© l‚Äôexistence de nombreux mod√®les statistiques permettant de pr√©dire <span class="math inline">\(Y\)</span> connaissant les caract√©ristiques <span class="math inline">\(\boldsymbol{x}\)</span> d‚Äôun client et que nous discuterons en partie¬†<a href="#chap1:sec3" data-reference-type="ref" data-reference="chap1:sec3">1.3</a>, la r√©gression logistique est tr√®s largement utilis√©e en <em>Credit Scoring</em>¬†<a href="#thomas2000survey" class="citation" data-cites="thomas2000survey">[20]</a>. Plusieurs travaux empiriques ont sugg√©r√© que du fait du faible nombre de covariables et de classes tr√®s m√©lang√©es (en particulier, absence de fronti√®re de s√©paration lin√©aire entre ‚Äúbons‚Äù et ‚Äúmauvais‚Äù clients), aucun autre mod√®le de classification supervis√©e ne produit de r√©sultats significativement sup√©rieurs √† la r√©gression logistique sur les donn√©es √† disposition de leurs auteurs respectifs (se r√©f√©rer par exemple √†¬†<a href="#hand1997statistical" class="citation" data-cites="hand1997statistical">[23]<a href="#baesens2003benchmarking" class="citation" data-cites="baesens2003benchmarking">[17]<a href="#brown2012experimental" class="citation" data-cites="brown2012experimental">[18]</a>).</p>
                                        <p>Le mod√®le de r√©gression logistique, contrairement √† ce que son nom sugg√®re, est un mod√®le de classification qui impose une structure particuli√®re de loi de probabilit√© d‚Äôune variable al√©atoire cible binaire <span class="math inline">\(Y\)</span> conditionnellement √† des covariables <span class="math inline">\(\boldsymbol{x} \in \mathcal{X}=\mathbb{R}^d\)</span> donn√©e par : <br /><span class="math display">$$\label{eq:logit}
                                            \text{logit}[p(Y=1 | \boldsymbol{x}=\boldsymbol{x}, \boldsymbol{\theta})] = \ln \frac{p(Y=1 | \boldsymbol{x}=\boldsymbol{x}, \boldsymbol{\theta})}{1-p(Y=1 | \boldsymbol{x}=\boldsymbol{x}, \boldsymbol{\theta})} = (1,\boldsymbol{x})' \boldsymbol{\theta}.$$</span><br /> Le vecteur <span class="math inline">\(\boldsymbol{\theta} = (\theta_0,\dots,\theta_d) \in \Theta = \mathbb{R}^{d+1}\)</span> est appel√© param√®tre. Le coefficient <span class="math inline"><em>Œ∏</em><sub>0</sub></span> d√©finit le biais, c‚Äôest-√†-dire <span class="math inline">\(\text{logit}[p(Y=1 | \boldsymbol{x}=\boldsymbol{0}, \boldsymbol{\theta})]\)</span>. Cette relation est ensuite invers√©e afin d‚Äôobtenir la probabilit√© d‚Äô√™tre ‚Äúbon‚Äù sachant les caract√©ristiques d‚Äôun client et le param√®tre <span class="math inline">\(\boldsymbol{\theta}\)</span> : <br /><span class="math display">$$p(Y=1 | \boldsymbol{x}=\boldsymbol{x}, \boldsymbol{\theta}) = \frac{1}{1+\exp(-(1,\boldsymbol{x})' \boldsymbol{\theta})},$$</span><br /> et dont des exemples de courbe sont donn√©s en figure¬†<a href="#fig:logit" data-reference-type="ref" data-reference="fig:logit">[4]</a>.</p>
                                        <figure>
                                            <img src="figures/chapitre1/fig_logit.png" alt="[4] Deux exemples de courbes logistiques √† une variable explicative sans param√®tre de biais." style="width:15cm" /><figcaption><span id="fig:logit" label="fig:logit">[4]</span> Deux exemples de courbes logistiques √† une variable explicative sans param√®tre de biais.</figcaption>
                                        </figure>

                                        <p>On peut facilement √©tendre ce mod√®le aux variables cat√©gorielles <span class="math inline">\(X_j \in \mathbb{N}_{o_j}\)</span> en proc√©dant √† un encodage <em>one-hot</em>, c‚Äôest-√†-dire en cr√©ant une matrice dite ‚Äúdisjonctive‚Äù √† <span class="math inline"><em>i</em></span> lignes (correspondant toujours √† chaque individu <span class="math inline">1‚ÄÑ‚â§‚ÄÑ<em>i</em>‚ÄÑ‚â§‚ÄÑ<em>n</em></span>) et <span class="math inline">\(l_j\)</span> colonnes binaires (correspondant respectivement √† la pr√©sence ou l‚Äôabsence de chaque modalit√©). √Ä l‚Äôindice <span class="math inline">\((i,‚ÄÜk)\)</span> de cette matrice, on trouve la valeur 1 si <span class="math inline">\(x_{i,j} = k\)</span>, pour toute modalit√© <span class="math inline">\(1 \leq k \leq l_j\)</span>, 0 sinon. Par exemple pour <span class="math inline">\(l_j=3\)</span>, un encodage possible est : <br /><span class="math display">$$\left( \begin{array}{c} 1 \\ 2 \\ 3 \end{array} \right) \to \left( \begin{array}{ccc} 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 \end{array} \right).$$</span><br /> Cette pratique conduit cependant √† une sur-param√©trisation : la somme des colonnes pour chaque ligne vaut 1 et la matrice de design, compl√©t√©e d‚Äôune premi√®re colonne de <span class="math inline">1</span> pour le terme d‚Äôintercept, n‚Äôest alors pas de plein-rang, ce qui pose un probl√®me pour l‚Äôestimation de <span class="math inline">\(\boldsymbol{\theta}\)</span> comme nous le verrons en partie¬†<a href="#chap1:sec3" data-reference-type="ref" data-reference="chap1:sec3">1.3</a> ; il faut donc ‚Äúsupprimer‚Äù une colonne en consid√©rant une modalit√© dite de r√©f√©rence (<em>i.e.</em>¬†pour laquelle le coefficient est nul). Cet encodage est implicite dans de nombreux logiciels statistiques, si bien que l‚Äôon notera les coefficients de r√©gression logistique associ√©s √† chaque valeur d‚Äôune variable cat√©gorielle <span class="math inline">\(X_j\)</span> en exposant : <span class="math inline">\(\theta_j^{1},\dots,\theta_j^{l_j}\)</span>. On consid√©rera la derni√®re modalit√© comme r√©f√©rence, d‚Äôo√π <span class="math inline">\(\theta_j^{l_j} = 0\)</span>.</p>
                                        <p>En fonction du risque que l‚Äôinstitut financier est pr√™t √† prendre, on d√©cide d‚Äôun <span data-acronym-label="cut" data-acronym-form="singular+short">cut</span>, c‚Äôest-√†-dire d‚Äôune probabilit√© de d√©faut au-del√† de laquelle on refuse la demande de cr√©dit. On d√©signe traditionnellement par <span data-acronym-label="score" data-acronym-form="singular+short">score</span> la fonction <span class="math inline">\(S(\cdot,\boldsymbol{\theta}): \boldsymbol{x} \mapsto (1,\boldsymbol{x})' \boldsymbol{\theta}\)</span>.</p>
                                        <p>La question du support de <span class="math inline">\(\boldsymbol{\theta}\)</span>, <em>i.e.</em>¬†de ses composantes non nulles, est un probl√®me plus connu sous le nom de ‚Äús√©lection de variables‚Äù en statistiques comme en <em>machine learning</em>. Un coefficient nul t√©moigne du fait que la variable associ√©e <span class="math inline">\(X_j\)</span>, conditionnellement aux autres variables que l‚Äôon notera <span class="math inline">\(\boldsymbol{X}_{-\{j\}}\)</span> dans la suite, ne permet pas d‚Äôexpliquer <span class="math inline">\(Y\)</span>. En industrie, il est courant de commencer par s√©lectionner les variables dont la corr√©lation avec la variable cible est jug√©e suffisante. Cette technique univari√©e ne permet pas de rendre compte de ph√©nom√®nes multivari√©es comme la redondance d‚Äôinformation entre covariables ou, √† l‚Äôinverse, la qualit√© pr√©dictive d‚Äôune variable dont la corr√©lation avec la cible peut √™tre faible mais qui apporterait une information conditionnellement aux autres variables explicatives. La communaut√© statistique a donc d√©velopp√© des outils sp√©cifiques √† cette question que l‚Äôon d√©veloppera, avec les fondements th√©oriques des mod√®les param√©triques comme la r√©gression logistique, en partie¬†<a href="#chap1:sec3" data-reference-type="ref" data-reference="chap1:sec3">1.3</a>.</p>
                                        <h3 id="subsec:gini">La m√©trique de performance</h3>
                                        <p>La m√©trique utilis√©e pour comparer la qualit√© de <span data-acronym-label="score" data-acronym-form="plural+short">scores</span> (le score ancien et un nouveau score propos√© par exemple) est traditionnellement l‚Äôindice de Gini, qui est en fait directement li√© √† l‚Äôaire sous la courbe (AUC) ROC. Cette courbe repr√©sente la sensibilit√© d‚Äôun classificateur binaire (<em>i.e.</em>¬†la proportion de ‚Äúbons‚Äù clients class√©s comme ‚Äúbons‚Äù) en fonction de son antisp√©cificit√© (<span class="math inline">1‚àí</span> la sp√©cificit√©, <em>i.e.</em>¬†la proportion de ‚Äúmauvais‚Äù clients class√©s comme ‚Äúbons‚Äù). L‚ÄôAUC s‚Äôinterpr√®te de plusieurs mani√®res, dont par exemple la probabilit√© qu‚Äôun ‚Äúbon‚Äù (tir√© al√©atoirement parmi les ‚Äúbons‚Äù) ait un score plus √©lev√© qu‚Äôun ‚Äúmauvais‚Äù (tir√© al√©atoirement parmi les ‚Äúmauvais‚Äù). Un exemple de courbe ROC est donn√© en figure¬†<a href="#fig:ROC" data-reference-type="ref" data-reference="fig:ROC">[5]</a>.</p>
                                        <figure>
                                            <img src="figures/chapitre1/fig_ROC.png" alt="[5] Exemple de courbe ROC sur un petit jeu de donn√©es simul√©es et valeur de l‚ÄôAUC correspondante." style="width:15cm" /><figcaption><span id="fig:ROC" label="fig:ROC">[5]</span> Exemple de courbe ROC sur un petit jeu de donn√©es simul√©es et valeur de l‚ÄôAUC correspondante.</figcaption>
                                        </figure>
                                        
                                        <p>Il faut remarquer √† ce stade que ce crit√®re est √† la fois diff√©rent de celui optimis√© par la r√©gression logistique, que nous verrons en d√©tails dans la partie suivante, et de l‚Äôobjectif industriel de maximiser le profit, soit directement par l‚Äôusage de variables de nature financi√®re¬†<a href="#finlay2010credit" class="citation" data-cites="finlay2010credit">[21]</a>, soit indirectement par le choix d‚Äôun <span data-acronym-label="cut" data-acronym-form="singular+short">cut</span> appropri√©. N√©anmoins, une √©tude empirique¬†<a href="#finlay2009we" class="citation" data-cites="finlay2009we">[22]</a> montre que la maximisation de ces diff√©rents objectifs est <em>a priori</em> relativement √©quivalente, la qualit√© pr√©dictive de diff√©rents mod√®les maximisant chacun de ces objectifs √©tant similaire sur le jeu de donn√©es consid√©r√© par l‚Äôauteur. On suppose cette √©quivalence dans la suite et sauf indication contraire, les r√©sultats sur donn√©es r√©elles sont donn√©s en Gini, dont on donnera un intervalle de confiance selon la m√©thode d√©velopp√©e dans¬†<a href="#sun2014fast" class="citation" data-cites="sun2014fast">[15]</a>.</p>
                                        <h3 id="suivi-temporel-de-la-performance-du-score">Suivi temporel de la performance du <span data-acronym-label="score" data-acronym-form="singular+short">score</span></h3>
                                        <p>Les changements de contexte √©conomique, agissant √† la fois sur le vecteur de variables explicatives <span class="math inline">\(\boldsymbol{x} = (x_1, \dots, x_d)\)</span> d√©fini en section¬†<a href="#subsec:apprentissage" data-reference-type="ref" data-reference="subsec:apprentissage">1.2.4</a> et repr√©sentant les caract√©ristiques du client (l‚Äôinflation ou le passage √† l‚Äôeuro impacte l‚Äô√©chelle des salaires par exemple) et la variable cible (la r√©cession entra√Æne l‚Äôaugmentation des impay√©s), la performance du <span data-acronym-label="score" data-acronym-form="singular+short">score</span>, selon la m√©trique pr√©c√©demment d√©crite, √©volue au cours du temps. Naturellement, cette √©volution est la plupart du temps √† la baisse puisque la fonction de <span data-acronym-label="score" data-acronym-form="singular+short">score</span> apprise s‚Äô√©loigne de la v√©rit√©. Par ailleurs, comme vu en partie¬†<a href="#subsec:critere" data-reference-type="ref" data-reference="subsec:critere">1.2.3</a>, l‚Äôapprentissage du <span data-acronym-label="score" data-acronym-form="singular+short">score</span> n√©cessite environ 30 mois de recul, auxquels peuvent s‚Äôajouter un d√©lai de mise en production. D√®s lors, le statisticien voit √©merger deux questions : premi√®rement, quels sont les ‚Äúsignes‚Äù indiquant qu‚Äôune refonte, c‚Äôest-√†-dire la mise en place d‚Äôun nouveau mod√®le pr√©dictif, est n√©cessaire ? Deuxi√®mement, est-il possible de construire un mod√®le pr√©dictif ‚Äúrobuste‚Äù √† ce probl√®me, commun√©ment d√©sign√© par <em>population drift</em> dans la litt√©rature¬†<a href="#hand1997statistical" class="citation" data-cites="hand1997statistical">[23]</a> ?</p>
                                        <p>En pratique, seules la baisse de performance d‚Äôun <span data-acronym-label="score" data-acronym-form="singular+short">score</span> et / ou son anciennet√© importante (5 √† 10 ans) conduisent √† sa refonte et l‚Äôaspect temporel n‚Äôest pas pris en compte dans la construction ou l‚Äôutilisation des <span data-acronym-label="score" data-acronym-form="plural+short">scores</span>.</p>
                                        
                                        <p>En conclusion, le <em>Credit Scoring</em> repose sur des bases statistiques qui soul√®vent de nombreuses questions, dont certaines trouvent dans le milieu industriel une r√©ponse <em>ad hoc</em>, tr√®s empirique, qu‚Äôil convient de formaliser. La partie suivante plonge l‚Äôapprentissage du <span data-acronym-label="score" data-acronym-form="singular+short">score</span> dans le contexte de l‚Äôapprentissage statistique.</p>
                                        <h2 id="chap1:sec3">Apprentissage statistique : fondements th√©oriques du <em>Credit Scoring</em></h2>
                                        <p>Apr√®s cette mise en situation industrielle qui aura mis en avant les approximations statistiques et autres heuristiques actuellement utilis√©es dans le milieu bancaire, il convient de formaliser les concepts introduits en partie¬†<a href="#chap1:sec2" data-reference-type="ref" data-reference="chap1:sec2">1.2</a>. Cette partie s‚Äôinspire librement d‚Äôintroductions de plusieurs ouvrages, dont le bien connu¬†¬†<a href="#friedman2001elements" class="citation" data-cites="friedman2001elements">[24]</a>.</p>
                                        <h3 id="m√©canisme-de-g√©n√©ration-des-donn√©es">M√©canisme de g√©n√©ration des donn√©es</h3>
                                        <p>On rappelle bri√®vement les notations introduites dans la partie pr√©c√©dente¬†: les clients ont <span class="math inline"><em>d</em></span> caract√©ristiques indic√©es par <span class="math inline"><em>j</em>‚ÄÑ=‚ÄÑ1,‚ÄÜ‚Ä¶,‚ÄÜ<em>d</em></span> dans la suite du manuscrit. Une caract√©ristique <span class="math inline">\(X_j\)</span> est une variable al√©atoire dont on notera la r√©alisation <span class="math inline">\(x_j\)</span>. L‚Äôaggr√©gation de toutes ces caract√©ristiques sous la forme d‚Äôun vecteur al√©atoire est distingu√©e, comme les autres vecteurs du manuscrit, par une police grasse, en l‚Äôoccurence <span class="math inline">\(\boldsymbol{x}\)</span>. Ce vecteur appartient √† l‚Äôespace <span class="math inline">\(\mathcal{X}\)</span> qui est un produit de <span class="math inline">\(\mathbb{R}\)</span> (variables continues) ou <span class="math inline">\(\mathbb{N}_{o_j}\)</span> (variables cat√©gorielles √† <span class="math inline">\(l_j\)</span> modalit√©s). La variable al√©atoire binaire √† pr√©dire, le caract√®re bon / mauvais d‚Äôun client, et sa r√©alisation sont not√©es respectivement <span class="math inline">\(Y \in \{0,1\}\)</span> et <span class="math inline">\(Y\)</span>. Le m√™me raisonnement s‚Äôapplique √† la variable al√©atoire binaire de financement / non financement et sa r√©alisation, not√©es respectivement <span class="math inline">\(z \in \{\text{f},\text{nf}\}\)</span> et <span class="math inline">\(z\)</span>. Enfin, on dispose d‚Äôun <span class="math inline"><em>n</em></span>-√©chantillon <span class="math inline">\(\mathcal{T} = (\boldsymbol{\mathbf{x}},\boldsymbol{\mathbf{y}},\mathbf{\boldsymbol{z}})\)</span>, o√π, <span class="math inline">\(\boldsymbol{\mathbf{x}} = (\boldsymbol{x}_i)_1^n\)</span>, <span class="math inline">\(\boldsymbol{\mathbf{y}} = (Y_i)_1^n\)</span> et <span class="math inline">\(\mathbf{\boldsymbol{z}} = (z_i)_1^n\)</span>.</p>
                                        <p>On note <span class="math inline"><em>p</em></span> la <span data-acronym-label="pdf" data-acronym-form="singular+short">pdf</span> de <span class="math inline">\((\boldsymbol{x},Y)\)</span> et <span class="math inline">\(p(\cdot | \boldsymbol{x})\)</span> la loi de probabilit√© de <span class="math inline"><em>Y</em></span> sachant <span class="math inline">\(\boldsymbol{x}\)</span>, qui s‚Äôobtient √† partir de <span class="math inline"><em>p</em></span> et de la relation de Bayes: <br /><span class="math display">$$p(Y | \boldsymbol{x}) = \frac{p(\boldsymbol{x},y)}{p(\boldsymbol{x})},$$</span><br /> que l‚Äôon d√©signera par ‚Äúoracle‚Äù dans la suite. On aimerait ‚Äúretrouver‚Äù cette loi par calcul, or elle est inconnue (si elle √©tait connue, le probl√®me serait r√©solu !), et on a uniquement acc√®s au <span class="math inline"><em>n</em></span>-√©chantillon <span class="math inline">\(\mathcal{T}\)</span>.</p>
                                        <p>Imaginons un instant que <span class="math inline">\(p(\cdot | \boldsymbol{x})\)</span> soit connu. Une premi√®re approche consiste en quelque sorte √† exprimer notre connaissance de cette loi en la for√ßant √† appartenir √† un mod√®le (ou √† une famille de mod√®les). Autrement dit, on suppose que <span class="math inline">\(p(\cdot | \boldsymbol{x})\)</span> appartient √† un ensemble (tr√®s) restreint des lois possibles. Comme √©nonc√© plus haut, dans le cadre du <em>Credit Scoring</em>, on s‚Äôint√©resse au mod√®le de r√©gression logistique¬†<a href="#eq:logit" data-reference-type="eqref" data-reference="eq:logit">[eq:logit]</a> not√© <span class="math inline">\(p_{\boldsymbol{\theta}}(\cdot | \boldsymbol{x})\)</span> dans la suite. D√®s lors, une formulation simple du probl√®me consiste √† se donner une notion de distance entre <span class="math inline">\(p(\cdot | \boldsymbol{x})\)</span> et <span class="math inline">\(p_{\boldsymbol{\theta}}(\cdot | \boldsymbol{x})\)</span> afin d‚Äôestimer le ‚Äúmeilleur‚Äù param√®tre <span class="math inline">\(\boldsymbol{\theta}^\star\)</span> au sens de cette ‚Äúdistance‚Äù. Un bon candidat est la divergence de Kullback-Leibler¬†<a href="#kullback1951information" class="citation" data-cites="kullback1951information">[19]</a> : <br /><span class="math display">$$\label{eq:KL}
                                            \text{KL}(p(\cdot | \boldsymbol{x})||p_{\boldsymbol{\theta}}(\cdot | \boldsymbol{x})) = \sum_{y \in \{0,1\}} p(y | \boldsymbol{x}) \ln \left( \frac{p(y | \boldsymbol{x})}{p_{\boldsymbol{\theta}}(y | \boldsymbol{x})} \right).$$</span><br /> Cette divergence est donn√©e pour une valeur particuli√®re <span class="math inline">\(\boldsymbol{x}\)</span> de <span class="math inline">\(\boldsymbol{x}\)</span>. Or, l‚Äôinstitut financier voudrait que le mod√®le <span class="math inline">\(p_{\boldsymbol{\theta}}(\cdot | \boldsymbol{x})\)</span> soit similaire √† <span class="math inline">\(p(\cdot | \boldsymbol{x})\)</span> en moyenne pour tous ses clients, ce qui conduit au param√®tre <br /><span class="math display">$${\boldsymbol{\theta}^\star} = \arg\min_{\boldsymbol{\theta}} \mathbb{E}_{\boldsymbol{x}} [\text{KL}(p(\cdot | \boldsymbol{x})||p_{\boldsymbol{\theta}}(\cdot | \boldsymbol{x}))].$$</span><br /> Comme <span class="math inline">\(\text{KL}(p(\cdot | \boldsymbol{x})||p_{\boldsymbol{\theta}}(\cdot | \boldsymbol{x})) \geq 0\)</span>, on peut voir cette op√©ration comme une projection de la loi <span class="math inline">\(p(\cdot | \boldsymbol{x})\)</span> dans l‚Äôespace du mod√®le (ou de la famille de mod√®les), illustr√©e sur la figure¬†<a href="#fig:projection" data-reference-type="ref" data-reference="fig:projection">[6]</a>. Cette interpr√©tation g√©om√©trique permet d‚Äôaffirmer que si <span class="math inline">\(\min_{\boldsymbol{\theta}} \mathbb{E}_{\boldsymbol{x}} [\text{KL}(p(\cdot | \boldsymbol{x})||p_{\boldsymbol{\theta}}(\cdot | \boldsymbol{x}))] = 0\)</span>, alors on a pour tout <span class="math inline">\(\boldsymbol{x}\)</span>, <span class="math inline">\(p(\cdot | \boldsymbol{x}) = p_{\boldsymbol{\theta}^\star}(\cdot | \boldsymbol{x})\)</span>. Dans ce cas, on parlera dans la suite de ‚Äúvrai mod√®le‚Äù ; dans le cas contraire, de ‚Äúmod√®le mal sp√©cifi√©‚Äù (anglicisme de <em>misspecified model</em>).</p>
                                        <figure>
                                            <img src="figures/chapitre1/fig_projection.png" alt="[6] Vision g√©om√©trique du biais de mod√®le." style="width:15cm" /><figcaption><span id="fig:projection" label="fig:projection">[6]</span> Vision g√©om√©trique du biais de mod√®le.</figcaption>
                                        </figure>

                                        <p>N‚Äôayant acc√®s √† <span class="math inline">\(p(\cdot | \boldsymbol{x})\)</span> qu‚Äô√† travers un √©chantillon, il nous faut d√©velopper un crit√®re empirique √† partir du crit√®re th√©orique (souvent de nature asymptotique) donn√© ici.</p>
                                        <h3 id="subsec:gradient">Minimisation du risque empirique et maximum de vraisemblance</h3>
                                        <p>On peut r√©√©crire <span class="math inline">\(\text{KL}(p(\cdot|\boldsymbol{x})||p_{\boldsymbol{\theta}}(\cdot|\boldsymbol{x}))\)</span> pour faire appara√Ætre une quantit√© ind√©pendante de <span class="math inline">\(p_{\boldsymbol{\theta}}\)</span> : <br /><span class="math display">$$\text{KL}(p(\cdot|\boldsymbol{x})||p_{\boldsymbol{\theta}}(\cdot|\boldsymbol{x})) = \sum_{y \in \{0,1\}} p(y|\boldsymbol{x}) \ln [p(y|\boldsymbol{x})] - \underbrace{\sum_{y \in \{0,1\}} p(y|\boldsymbol{x}) \ln [p_{\boldsymbol{\theta}}(y|\boldsymbol{x})]}_{\mathbb{E}_{Y | \boldsymbol{x} = \boldsymbol{x}} [\ln[p_{\boldsymbol{\theta}}(\cdot|\boldsymbol{x})]]}.$$</span><br /> On va donc naturellement se concentrer sur la maximisation du second terme pour l‚Äôensemble des clients en moyenne, c‚Äôest-√†-dire <br /><span class="math display">$$\boldsymbol{\theta}^\star = \arg\max_{\boldsymbol{\theta}} \mathbb{E}_{\boldsymbol{x}}  [\mathbb{E}_{Y | \boldsymbol{x}} [\ln[p_{\boldsymbol{\theta}}(\cdot|\boldsymbol{x})]]] = \arg\max_{\boldsymbol{\theta}} \mathbb{E}_{(\boldsymbol{x},Y) \sim p} [\ln[p_{\boldsymbol{\theta}}(Y | \boldsymbol{x})]].$$</span><br /></p>
                                        <p>On se place dans le cadre d‚Äôun <span class="math inline"><em>n</em></span>-√©chantillon i.i.d.¬†ce qui est toujours le cas en <em>Credit Scoring</em> sous r√©serve que les cr√©dits observ√©s soient issus de clients diff√©rents (ce que l‚Äôon supposera dans la suite). L‚Äôhypoth√®se d‚Äôind√©pendance nous permet aussi d‚Äôapproximer l‚Äôesp√©rance sur <span class="math inline">\(\mathcal{X} \times \mathcal{Y}\)</span> par l‚Äôesp√©rance sur l‚Äô√©chantillon et on obtient le crit√®re <span class="math inline">\(\ell(\theta;\boldsymbol{\mathbf{x}},\boldsymbol{\mathbf{y}})\)</span> : <br /><span class="math display">$$\label{eq:vraisemblance}
                                            \ell(\boldsymbol{\theta};\boldsymbol{\mathbf{x}},\boldsymbol{\mathbf{y}}) = \sum_{i=1}^n \ln[p_{\boldsymbol{\theta}}(y_i | \boldsymbol{x}_i) ].$$</span><br /> Ce crit√®re correspond en fait au maximum de vraisemblance : la probabilit√© d‚Äôobserver les donn√©es <span class="math inline">\(\boldsymbol{\mathbf{y}}\)</span> sachant les covariables <span class="math inline">\(\boldsymbol{\mathbf{x}}\)</span> et le param√®tre <span class="math inline">\(\boldsymbol{\theta}\)</span>. L‚Äôhypoth√®se d‚Äôind√©pendance nous permet d‚Äô√©crire la vraisemblance sous la forme d‚Äôun produit : <br /><span class="math display">$$\mathcal{L}(\boldsymbol{\theta};\boldsymbol{\mathbf{x}},\boldsymbol{\mathbf{y}}) = p_{\boldsymbol{\theta}}(y_1,\dots,y_n | \boldsymbol{x}_1,\dots \boldsymbol{x}_n) = \prod_{i=1}^n p_{\boldsymbol{\theta}}(y_i | \boldsymbol{x}_i).$$</span><br /> En passant cette expression au logarithme, fonction strictement croissante, on retrouve bien la formulation de <span class="math inline">\(\ell(\boldsymbol{\theta};\boldsymbol{\mathbf{x}},\boldsymbol{\mathbf{y}})\)</span>.</p>
                                        <p>Dans la litt√©rature <em>machine learning</em>, o√π l‚Äôon minimise plut√¥t un risque empirique, sous-entendu de ‚Äúmauvais classement‚Äù au sens d‚Äôune fonction de co√ªt √† d√©finir, le maximum de vraisemblance est √©quivalent au minimum de la ‚Äúlog loss‚Äù. Dans la suite, on pr√©f√©rera la notion de vraisemblance.</p>
                                        <p>Dans le cas de la r√©gression logistique¬†<a href="#eq:logit" data-reference-type="eqref" data-reference="eq:logit">[eq:logit]</a>, la log-vraisemblance prend la forme suivante : <br /><span class="math display">$$\ell(\boldsymbol{\theta};\boldsymbol{\mathbf{x}},\boldsymbol{\mathbf{y}}) = \underbrace{\sum_{i=1}^n y_i (\boldsymbol{\theta}' \times (1,\boldsymbol{x}))}_{\text{fonction affine de } \boldsymbol{\theta}} - \underbrace{\ln(1 + \exp(\boldsymbol{\theta}' \times (1,\boldsymbol{x}))}_{\text{log-sum-exp d'une fonction affine de } \boldsymbol{\theta}}.$$</span><br /> Cette fonction est concave et tout maximum local est donc global.</p>
                                        <h4 id="passage-√†-la-d√©riv√©e-du-crit√®re-de-log-vraisemblance">Passage √† la d√©riv√©e du crit√®re de log-vraisemblance</h4>
                                        <p>Le ‚Äúr√©flexe‚Äù pour obtenir un maximum local conduit √† d√©river la fonction de vraisemblance et trouver <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> pour lequel cette d√©riv√©e est nulle : <br /><span class="math display">$$\dfrac{\partial \ell}{\partial \theta_j} (\hat{\boldsymbol{\theta}};\boldsymbol{\mathbf{x}},\boldsymbol{\mathbf{y}})= \sum_{i=1}^n (y_i - p_{\hat{\boldsymbol{\theta}}}(1|\boldsymbol{x}_i)) x_{i,j} = 0.$$</span><br /></p>
                                        <p>Cependant, contrairement √† la r√©gression lin√©aire o√π l‚Äôon dispose d‚Äôune formule explicite pour l‚Äôestimateur du maximum de vraisemblance <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span>, il n‚Äôexiste rien de tel pour la r√©gression logistique puisque cette √©quation n‚Äôest pas lin√©aire en <span class="math inline">\(\boldsymbol{\theta}\)</span> et l‚Äôon doit recourir √† des algorithmes it√©ratifs, dont le plus connu est la descente de gradient.</p>
                                        <h4 id="algorithmes-it√©ratifs-de-descente-de-gradient">Algorithmes it√©ratifs de descente de gradient</h4>
                                        <p>On d√©signe le gradient de la log-vraisemblance par rapport √† <span class="math inline">\(\boldsymbol{\theta}\)</span> par <span class="math inline">\(\nabla_{\boldsymbol{\theta}} \ell = \left( \dfrac{\partial \ell}{\partial \theta_j} \right)_0^d\)</span>. L‚Äôalgorithme de descente de gradient consiste √† mettre √† jour √† l‚Äô√©tape <span class="math inline">(<em>s</em>)</span> le param√®tre <span class="math inline">\(\boldsymbol{\theta}^{(s)}\)</span> dans la direction qui am√©liore le crit√®re <span class="math inline">\(\ell(\boldsymbol{\theta};\boldsymbol{\mathbf{x}},\boldsymbol{\mathbf{y}})\)</span> : <br /><span class="math display">$$\boldsymbol{\theta}^{(s+1)} = \boldsymbol{\theta}^{(s)} + \epsilon \nabla_{\boldsymbol{\theta}} \ell(\boldsymbol{\theta}^{(s)};\boldsymbol{\mathbf{x}},\boldsymbol{\mathbf{y}}).$$</span><br /> Une immense litt√©rature est d√©di√©e au choix de <span class="math inline"><em>œµ</em></span>, appel√© <em>learning rate</em> en <em>machine learning</em> et √† d‚Äôautres astuces destin√©es √† acc√©l√©rer la convergence √©ventuelle vers <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span>. Cette litt√©rature s‚Äôest particuli√®rement d√©velopp√©e dans le cadre des r√©seaux de neurones, pour lesquels la m√©thode de Newton, bien adapt√©e √† la r√©gression logistique et que l‚Äôon d√©veloppera ci-apr√®s, n‚Äôest pas adapt√©e.</p>
                                        <h4 id="m√©thode-de-newton-raphson">M√©thode de Newton-Raphson</h4>
                                        <p>On note la matrice hessienne de <span class="math inline">‚Ñì</span> en <span class="math inline">\(\boldsymbol{\theta}\)</span> par <span class="math inline">\(\mathbf{H}_{\boldsymbol{\theta}} = \left( \dfrac{\partial^2 \ell}{\partial \theta_j \partial \theta_k} \right)_{0 \leq j,k \leq d}\)</span>. Le d√©veloppement de Taylor, qui revient √† consid√©rer que la log-vraisemblance est localement quadratique, donne √† l‚Äô√©tape <span class="math inline">(<em>s</em>)</span> : <br /><span class="math display">$$\ell(\boldsymbol{\theta}^{(s+1)};\boldsymbol{\mathbf{x}},\boldsymbol{\mathbf{y}}) = \ell({\boldsymbol{\theta}}^{(s)};\boldsymbol{\mathbf{x}},\boldsymbol{\mathbf{y}}) + \nabla_{\boldsymbol{\theta}} \ell(\boldsymbol{\theta}^{(s)};\boldsymbol{\mathbf{x}},\boldsymbol{\mathbf{y}})' (\boldsymbol{\theta}^{(s+1)} - {\boldsymbol{\theta}}^{(s)}) + \dfrac{1}{2}(\boldsymbol{\theta}^{(s+1)} - {\boldsymbol{\theta}}^{(s)})'  \mathbf{H}_{{\boldsymbol{\theta}}}(\boldsymbol{\theta}^{(s)};\boldsymbol{\mathbf{x}},\boldsymbol{\mathbf{y}}) (\boldsymbol{\theta}^{(s+1)} - {\boldsymbol{\theta}}^{(s)}).$$</span><br /> En d√©rivant cette expression par rapport √† <span class="math inline">\(\boldsymbol{\theta}^{(s+1)}\)</span> et en remarquant que l‚Äôon souhaiterait arriver au maximum de <span class="math inline">‚Ñì</span> √† l‚Äô√©tape <span class="math inline">(<em>s</em>‚ÄÖ+‚ÄÖ1)</span>, autrement dit en posant <span class="math inline">\(\nabla_{\boldsymbol{\theta}} \ell(\boldsymbol{\theta}^{(s+1)};\boldsymbol{\mathbf{x}},\boldsymbol{\mathbf{y}})=0\)</span>, on obtient : <br /><span class="math display">$$0 = \nabla_{\boldsymbol{\theta}} \ell(\boldsymbol{\theta}^{(s)};\boldsymbol{\mathbf{x}},\boldsymbol{\mathbf{y}}) + (\boldsymbol{\theta}^{(s+1)} - {\boldsymbol{\theta}}^{(s)}) \mathbf{H}_{{\boldsymbol{\theta}}^{(s)}}(\boldsymbol{\theta}^{(s)};\boldsymbol{\mathbf{x}},\boldsymbol{\mathbf{y}}).$$</span><br /> En r√©arrangeant cette expression, on obtient la valeur mise √† jour du param√®tre : <br /><span class="math display">$$\boldsymbol{\theta}^{(s+1)} = \boldsymbol{\theta}^{(s)} - \mathbf{H}_{{\boldsymbol{\theta}}}(\boldsymbol{\theta}^{(s)};\boldsymbol{\mathbf{x}},\boldsymbol{\mathbf{y}})^{-1} \nabla_{\boldsymbol{\theta}} \ell(\boldsymbol{\theta}^{(s)};\boldsymbol{\mathbf{x}},\boldsymbol{\mathbf{y}}),$$</span><br /> o√π <span class="math inline">\(\nabla_{\boldsymbol{\theta}} \ell(\boldsymbol{\theta}^{(s)};\boldsymbol{\mathbf{x}},\boldsymbol{\mathbf{y}}) = (\boldsymbol{1},\boldsymbol{\mathbf{x}})' (\boldsymbol{\mathbf{y}} - \Pi)\)</span> et <span class="math inline">\(\mathbf{H}_{{\boldsymbol{\theta}}}(\boldsymbol{\theta}^{(s)};\boldsymbol{\mathbf{x}},\boldsymbol{\mathbf{y}}) = (\boldsymbol{1},\boldsymbol{\mathbf{x}}) \mathbf{W} (\boldsymbol{1},\boldsymbol{\mathbf{x}})'\)</span> avec <span class="math inline">\(\Pi = (p_{\boldsymbol{\theta}^{(s)}}(1|\boldsymbol{x}_1),\dots,p_{\boldsymbol{\theta}^{(s)}}(1|\boldsymbol{x}_n))\)</span> et <span class="math inline"><strong>W</strong>‚ÄÑ=‚ÄÑdiag(<em>Œ†</em>‚ÄÖ‚äô‚ÄÖ(<strong>1</strong>‚ÄÖ‚àí‚ÄÖ<em>Œ†</em>))</span> o√π <span class="math inline">‚äô</span> d√©signe le produit d‚ÄôHadamard (<em>i.e.</em>¬†√©l√©ment par √©l√©ment). Plusieurs points importants transparaissent de cette derni√®re √©quation. D‚Äôabord, si √† une √©tape <span class="math inline">(<em>s</em>)</span>, le point fixe est trouv√©, <em>i.e.</em>¬†<span class="math inline">\(\boldsymbol{\theta}^{(s)} = \hat{\boldsymbol{\theta}}\)</span>, alors <span class="math inline">\(\nabla_{\boldsymbol{\theta}} \ell(\boldsymbol{\theta}^{(s)};\boldsymbol{\mathbf{x}},\boldsymbol{\mathbf{y}}) = 0\)</span> et on ne bouge plus : <span class="math inline">\(\forall s' \geq s, \: \boldsymbol{\theta}^{(s')} = \boldsymbol{\theta}^{(s)}\)</span>. En pratique, cela conduit la majorit√© des biblioth√®ques logicielles impl√©mentant la m√©thode de Newton √† laisser √† leur utilisateur le soin de calibrer deux param√®tres : la pr√©cision au-del√† de laquelle l‚Äôalgorithme s‚Äôarr√™te, c‚Äôest-√†-dire <span class="math inline"><em>Œ∑</em></span> tel que s‚Äôil existe <span class="math inline"><em>s</em></span> tel que <span class="math inline">\(||\boldsymbol{\theta}^{(s+1)} - \boldsymbol{\theta}^{(s)}||_{\infty} \leq \eta\)</span>, o√π <span class="math inline">\(|| \boldsymbol{x} ||_{\infty} = \max_{j} |x_j|\)</span>, alors <span class="math inline">\(\hat{\boldsymbol{\theta}} \approx \boldsymbol{\theta}^{(s+1)}\)</span> et le nombre de pas maximum <span class="math inline"><em>s</em><sub>max</sub></span> √† effectuer (la condition pr√©c√©dente n‚Äô√©tant potentiellement jamais remplie, l‚Äôalgorithme pourrait ne pas se terminer). Une revue des principales m√©thodes d‚Äôoptimisation utilisables dans le cadre de la r√©gression logistique, suivie de leur √©tude empirique¬†<a href="#minka2003comparison" class="citation" data-cites="minka2003comparison">[11]</a> montre que l‚Äôalgorithme de Newton et la m√©thode BFGS¬†<a href="#byrd1995limited" class="citation" data-cites="byrd1995limited">[10]</a>, de complexit√© respective <span class="math inline"><em>O</em>(<em>n</em><em>d</em><sup>2</sup>)</span> et <span class="math inline"><em>O</em>(<em>d</em><sup>2</sup>‚ÄÖ+‚ÄÖ<em>n</em><em>d</em>)</span> pr√©sentent un bon compromis pr√©cision / co√ªt de calcul lorsque compar√©es √† d‚Äôautres m√©thodes de descente de gradient et sous diff√©rents sc√©narios de g√©n√©ration des donn√©es. Tous les param√®tres de r√©gression logistique de ce manuscrit sont par cons√©quent estim√©es par l‚Äôalgorithme de Newton, car √† l‚Äôexception des remarques sur la grande dimension donn√©es en conclusion, le nombre de covariables <span class="math inline"><em>d</em></span> est faible (<span class="math inline">10</span>-<span class="math inline">100</span>) relativement √† <span class="math inline"><em>n</em></span> (<span class="math inline">10<sup>5</sup></span>-<span class="math inline">10<sup>6</sup></span>). Enfin, l‚Äôalgorithme requiert une initialisation <span class="math inline">\(\boldsymbol{\theta}^{(0)}\)</span> qui peut en influencer la vitesse de convergence. Les biblioth√®ques utilisent g√©n√©ralement <span class="math inline">\(\boldsymbol{\theta}^{(0)}=0\)</span>.</p>
                                        <h4 id="subsubsec:tradeoff">Compromis biais-variance</h4>
                                        <p>En conclusion, l√† o√π le probabiliste, en figure¬†<a href="#fig:projection" data-reference-type="ref" data-reference="fig:projection">[6]</a> n‚Äôavait qu‚Äôun probl√®me de biais de mod√®le, le statisticien qui souhaite estimer ce mod√®le √† partir de donn√©es est pr√©occup√© par deux probl√®mes suppl√©mentaires. Le premier est l‚Äôerreur d‚Äôestimation, c‚Äôest-√†-dire la diff√©rence entre le meilleur mod√®le de param√®tre <span class="math inline">\(\boldsymbol{\theta}^\star\)</span> et le mod√®le estim√© de param√®tre <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span>: <br /><span class="math display">$$\begin{aligned}
                                            &amp; \mathbb{E}_{\mathcal{T}} \mathbb{E}_{\boldsymbol{x}} [p_{\hat{\boldsymbol{\theta}}}(y| \boldsymbol{x}) - p(y| \boldsymbol{x})]^2  \nonumber \\
                                            = &amp; \mathbb{E}_{\boldsymbol{x}} [ \underbrace{[p(y| \boldsymbol{x}) - \mathbb{E}_{\mathcal{T}} [ p_{\hat{\boldsymbol{\theta}}}(y| \boldsymbol{x})]]^2}_{\text{biais de mod√®le}} + \underbrace{\mathbb{E}_{\mathcal{T}} [[ p_{\hat{\boldsymbol{\theta}}}(y| \boldsymbol{x}) - \mathbb{E}_{\mathcal{T}} [ p_{\hat{\boldsymbol{\theta}}}(y| \boldsymbol{x}) ]]^2]}_{\text{variance}} ] \label{eq:bias1} \\
                                            \approx &amp; \mathbb{E}_{\boldsymbol{x}} [ \underbrace{[p(y| \boldsymbol{x}) - p_{\boldsymbol{\theta}^\star}(y| \boldsymbol{x})]^2}_{\text{biais de mod√®le}} + \underbrace{\mathbb{E}_{\mathcal{T}} [[ p_{\hat{\boldsymbol{\theta}}}(y| \boldsymbol{x}) - p_{\boldsymbol{\theta}^\star}(y| \boldsymbol{x})  ]^2}_{\text{erreur d'estimation}} ]]. \label{eq:bias2}\end{aligned}$$</span><br /> Pour la d√©rivation rigoureuse de ce r√©sultat, se r√©f√©rer √†¬†<a href="#schutze2008introduction" class="citation" data-cites="schutze2008introduction">[8]</a> (p.¬†308‚Äì314). Le passage de¬†<a href="#eq:bias1" data-reference-type="ref" data-reference="eq:bias1">[eq:bias1]</a> √†¬†<a href="#eq:bias2" data-reference-type="ref" data-reference="eq:bias2">[eq:bias2]</a> est garanti par le caract√®re asymptotiquement sans biais de l‚Äôestimateur du maximum de vraisemblance, m√™me dans le cas du mod√®le mal sp√©cifi√©¬†<a href="#white1982maximum" class="citation" data-cites="white1982maximum">[7]</a>. Autrement dit, pour <span class="math inline"><em>n</em></span> assez grand, on a <span class="math inline">\(\sqrt{n} (\hat{\boldsymbol{\theta}} - \boldsymbol{\theta}^\star) \sim \mathcal{N}(\boldsymbol{0} , \mathcal{I}(\boldsymbol{\theta}^\star)^{-1})\)</span>, o√π <span class="math inline">\(\mathcal{I}(\boldsymbol{\theta}) = - \mathbb{E}_{(\boldsymbol{x}, Y)}[ (\frac{\partial^2 \ln p_{\boldsymbol{\theta}}(Y | \boldsymbol{x})}{\partial \theta_j \partial \theta_k})_{0 \leq j,k, \leq d} | \boldsymbol{\theta}]\)</span> est la matrice d‚Äôinformation de Fisher. On a alors la consistance asymptotique en probabilit√© de l‚Äôestimateur du maximum de vraisemblance <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> vers <span class="math inline">\(\boldsymbol{\theta}^\star\)</span>. Le dernier terme de variance a √©t√© introduit en quelque sorte par le passage du crit√®re KL asymptotique¬†<a href="#eq:KL" data-reference-type="eqref" data-reference="eq:KL">[eq:KL]</a> au crit√®re empirique de vraisemblance¬†<a href="#eq:vraisemblance" data-reference-type="eqref" data-reference="eq:vraisemblance">[eq:vraisemblance]</a>. Ce terme est mat√©rialis√© en <span style="color: blue">bleu</span> sur la figure¬†<a href="#fig:projection2" data-reference-type="ref" data-reference="fig:projection2">[7]</a> Le deuxi√®me probl√®me est num√©rique et g√©n√©ralement n√©glig√© : il s‚Äôagit de l‚Äôerreur de pr√©cision d√©velopp√©e au paragraphe pr√©c√©dent et mat√©rialis√©e en <span style="color: orange">orange</span> sur la figure¬†<a href="#fig:projection2" data-reference-type="ref" data-reference="fig:projection2">[7]</a>.</p>
                                        <figure>
                                            <img src="figures/chapitre1/fig_projection2.png" alt="[7] Vision g√©om√©trique du biais de mod√®le, biais et variance d‚Äôestimation." style="width:15cm" /><figcaption><span id="fig:projection2" label="fig:projection2">[7]</span> Vision g√©om√©trique du biais de mod√®le, biais et variance d‚Äôestimation.</figcaption>
                                        </figure>

                                        <h3 id="s√©lection-de-mod√®le-en-credit-scoring">S√©lection de mod√®le en <em>Credit Scoring</em></h3>
                                        <p>Dans la partie pr√©c√©dente, on a r√©duit le probl√®me √† la seule estimation de <span class="math inline">\(\boldsymbol{\theta}\)</span>, et on a implicitement utilis√© l‚Äôensemble des <span class="math inline"><em>d</em></span> variables dans <span class="math inline">\(\boldsymbol{x}\)</span>. En th√©orie, se faisant, les variables ind√©pendantes de <span class="math inline"><em>Y</em></span> conditionnellement aux autres variables devraient avoir un coefficient <span class="math inline"><em>Œ∏</em><sub><em>j</em></sub></span> nul. C‚Äôest le cas lorsqu‚Äôune variable est totalement ind√©pendante de la cible, par exemple la m√©t√©o du jour de la demande du pr√™t, ou lorsqu‚Äôune variable est redondante avec une autre variable, par exemple les revenus annuels et mensuels qui sont √©gaux √† un facteur multiplicatif pr√®s.</p>
                                        <p>En pratique, tous les coefficients de <span class="math inline">\(\boldsymbol{\theta}\)</span> seront diff√©rents de <span class="math inline">0</span> du fait des deux ph√©nom√®nes illustr√©s sur le graphique¬†<a href="#fig:projection2" data-reference-type="ref" data-reference="fig:projection2">[7]</a> : l‚Äô(im)pr√©cision num√©rique abord√©e dans la partie pr√©c√©dente et le design <span class="math inline">\(\boldsymbol{\mathbf{x}}\)</span> fixe introduisant un biais et une variance d‚Äôestimation. C‚Äôest pourquoi il est n√©cessaire de s√©lectionner les ‚Äúbonnes‚Äù variables pr√©dictives parmi <span class="math inline">\(x_1,\dots,x_d\)</span> au sens d‚Äôun crit√®re que l‚Äôon d√©veloppe ci-apr√®s, afin de r√©duire l‚Äôerreur d‚Äôestimation.</p>
                                        <p>Par ailleurs et toujours dans le but de trouver un compromis entre biais de mod√®le et erreur d‚Äôestimation, il peut s‚Äôav√©rer n√©cessaire d‚Äôajouter des variables par calcul ou combinaison des variables <span class="math inline">\(x_1,\dots,x_d\)</span>. On s‚Äôint√©ressera plus pr√©cis√©ment aux processus de discr√©tisation de variables continues, de regroupement de modalit√©s de variables cat√©gorielles et d‚Äôintroduction d‚Äôinteractions, c‚Äôest-√†-dire de produits de variables pr√©-existantes.</p>
                                        <h4 id="subsubsec:selection">S√©lection de variables</h4>
                                        <p>Le premier r√©flexe du statisticien face √† un probl√®me de classification est la s√©lection de variables. A l‚Äôextr√™me, lorsque <span class="math inline"><em>d</em>‚ÄÑ&gt;‚ÄÑ<em>n</em></span>, le probl√®me est mal d√©fini (la matrice hessienne n‚Äôest pas inversible) ; dans une moindre mesure, lorsque <span class="math inline"><em>n</em>‚ÄÑ&gt;‚ÄÑ<em>d</em></span> mais que certaines variables n‚Äôont pas de pouvoir pr√©dictif conditionnellement √† celles d√©j√† dans le mod√®le, c‚Äôest-√†-dire par exemple <span class="math inline">\(p(y | \boldsymbol{x}) = p(y|x_2,\dots,x_d)\)</span>, alors le coefficient <span class="math inline"><em>Œ∏ÃÇ</em><sub>1</sub></span> ajoute une dimension ‚Äúinutile‚Äù √† l‚Äôespace <span class="math inline"><strong>Œò</strong></span> (on parle de la capacit√© d‚Äôun mod√®le en <em>machine learning</em>) qui augmente la variance du mod√®le <span class="math inline">\(p_{\boldsymbol{\theta}}\)</span> (on parle d‚Äô<em>overfitting</em> en <em>machine learning</em>) en essayant en quelque sorte de pr√©dire le bruit, c‚Äôest-√†-dire les r√©sidus du mod√®le. Dans les chapitres suivants, on utilisera abusivement la notation <span class="math inline"><em>p</em></span> pour toute <span data-acronym-label="pdf" data-acronym-form="singular+short">pdf</span> lorsque les variables dont elle d√©pend sont explicites.</p>
                                        <p>Dans le cas particulier du <em>Credit Scoring</em>, une th√®se CIFRE r√©cente a m√™me √©t√© consacr√©e au sujet de la s√©lection de variables¬†<a href="#vital2016" class="citation" data-cites="vital2016">[9]</a> et recommande l‚Äôutilisation de la proc√©dure LASSO, de la ‚Äúfamille‚Äù des m√©thodes de p√©nalisation : une contrainte est ajout√©e √† la vraisemblance pour l‚Äôoptimisation des param√®tres. Le crit√®re devient : <br /><span class="math display">$$\begin{aligned}
                                            \hat{\boldsymbol{\theta}}^{\text{Lasso}} &amp; = \arg\min_{\boldsymbol{\theta}} \ell(\boldsymbol{\theta};\boldsymbol{\mathbf{x}},\boldsymbol{\mathbf{y}}) \text{ avec } \sum_{j=1}^d |\boldsymbol{\theta}_j| \leq t \\
                                            &amp; = \arg\min_{\boldsymbol{\theta}}  \ell(\boldsymbol{\theta};\boldsymbol{\mathbf{x}},\boldsymbol{\mathbf{y}}) + \lambda \sum_{j=1}^d |\boldsymbol{\theta}_j|\end{aligned}$$</span><br /> o√π <span class="math inline"><em>t</em></span> et <span class="math inline"><em>Œª</em></span> sont mutuellement d√©pendants et r√®glent la s√©v√©rit√© de la r√©gularisation. De mani√®re g√©n√©rale, la r√©gularisation pr√©sente plusieurs avantages, et la motivation premi√®re est le contr√¥le du compromis biais-variance. N√©anmoins, par l‚Äôutilisation d‚Äôune p√©nalisation de type <span class="math inline"><em>L</em><sup>1</sup></span> comme le LASSO, un effet de bord d√©sirable est la s√©lection de variables, c‚Äôest-√†-dire la capacit√© √† ‚Äúforcer‚Äù des coefficients estim√©s exactement √† <span class="math inline">0</span>. Plusieurs variantes ou raffinements du LASSO existent aujourd‚Äôhui et poss√®dent des propri√©t√©s asymptotiques diff√©rentes ou meilleures.</p>
                                        <h4 id="subsubsec:choix_modele">Crit√®re de s√©lection de mod√®le</h4>
                                        <p>Une approche de r√©solution indirecte du probl√®me de s√©lection de variables est le choix de mod√®le : consid√©rons <span class="math inline"><em>M</em></span> mod√®les <span class="math inline"><em>Œò</em><sup>(1)</sup>,‚ÄÜ‚Ä¶,‚ÄÜ<em>Œò</em><sup>(<em>M</em>)</sup></span> de r√©gression logistique diff√©rents, c‚Äôest-√†-dire pour lesquels les variables incluses ne sont pas les m√™mes. On peut d‚Äôailleurs voir le probl√®me de s√©lection de variables comme un choix entre tous les <span class="math inline">2<sup><em>d</em></sup></span> mod√®les possibles. Dans ce cadre, de nombreux crit√®res de choix de mod√®le, voire d‚Äôaggr√©gation de mod√®les, c‚Äôest-√†-dire de s√©lection de tout ou partie de ces mod√®les en pond√©rant leur contribution globale, ont √©t√© propos√©s. La justification de ces crit√®res sort largement du cadre de ce manuscrit ; aussi nous nous limiterons, dans le cadre de la s√©lection de mod√®le, au crit√®re BIC (propos√© dans¬†<a href="#BIC" class="citation" data-cites="BIC">[6]</a>). Outre sa consistance asymptotique, autrement dit la capacit√© de s√©lectionner, sous certaines conditions sur la famille notamment, le ‚Äúquasi-vrai‚Äù mod√®le (le mod√®le de plus faible divergence <span class="math inline">\(\text{KL}\)</span> et de complexit√© <span class="math inline"><em>ŒΩ</em></span> minimale - cf ci-apr√®s) avec une probabilit√© tendant vers <span class="math inline">1</span> lorsque la taille d‚Äô√©chantillon <span class="math inline"><em>n</em></span> augmente, ce crit√®re poss√®de une propri√©t√© qui le lie √† la probabilit√© <em>a posteriori</em> d‚Äôun mod√®le conditionnellement aux donn√©es.</p>
                                        <p>Le crit√®re BIC s‚Äô√©crit de la mani√®re suivante et doit √™tre minimis√© : <br /><span class="math display">$$\label{eq:BIC}
                                            \text{BIC}(\hat{\boldsymbol{\theta}}) =  -2 \ell(\hat{\boldsymbol{\theta}} ; \boldsymbol{\mathbf{x}},\boldsymbol{\mathbf{y}}) + \nu \ln (n),$$</span><br /> o√π <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> est l‚Äôestimateur du maximum de vraisemblance et <span class="math inline"><em>ŒΩ</em>‚ÄÑ=‚ÄÑdim(<em>Œò</em>)</span>.</p>
                                        <h3 id="autres-mod√®les-pr√©dictifs">Autres mod√®les pr√©dictifs</h3>
                                        <p>L‚Äôobjectif de cette partie est de donner un √©clairage √† d‚Äôautres familles de mod√®les pr√©dictifs qui pourraient √™tre utilis√©s en lieu et place de la r√©gression logistique traditionnellement utilis√©e en <em>Credit Scoring</em> pour les nombreuses raisons pratiques et statistiques pr√©c√©demment √©voqu√©es.</p>
                                        <h4 id="arbres-de-d√©cision">Arbres de d√©cision</h4>
                                        <h5 id="principe">Principe</h5>
                                        <p>Toutes les observations entrent au sommet de l‚Äôarbre qui dispose d‚Äôun seul noeud. Ce noeud contient une r√®gle de classement parmi les noeuds fils de type <code>si ... alors ...</code>. Chacun de ces noeuds fils dispose alors d‚Äôun sous-ensemble des observations de d√©part, et la proc√©dure se r√©p√®te r√©cursivement jusqu‚Äôaux feuilles de l‚Äôarbre, c‚Äôest-√†-dire les noeuds d√©pourvus de fils, dont les observations sont affect√©es, dans le cadre de l‚Äôapprentissage supervis√©e, √† une classe bon / mauvais payeur. Cette structure est utilis√©e en <em>Credit Scoring</em> dans le cadre de la segmentation (section¬†<a href="#subsec:segmentation" data-reference-type="ref" data-reference="subsec:segmentation">1.2.2</a>), pratique que l‚Äôon revisite au chapitre¬†<a href="#chap6" data-reference-type="ref" data-reference="chap6">[chap6]</a> et o√π un exemple d‚Äôarbre est visible en figure¬†<a href="#fig:arbre" data-reference-type="ref" data-reference="fig:arbre">[8]</a>.</p>
                                        <figure>
                                            <img src="figures/chapitre1/fig_arbre.png" alt="[8] Simplified cartography of the application scorecards." style="width:15cm" /><figcaption><span id="fig:arbre" label="fig:arbre">[8]</span> Simplified cartography of the application scorecards.</figcaption>
                                        </figure>
                                        
                                        <h5 id="algorithmes">Algorithmes</h5>
                                        <p>Ainsi pos√©, l‚Äôarbre de d√©cision semble √† la fois simple dans sa formulation, et complexe dans la mise en oeuvre de son apprentissage : comment choisir les r√®gles de chaque noeud, le nombre de noeuds fils √† chaque noeud, le crit√®re d‚Äôarr√™t, etc. En pratique, de nombreux algorithmes ont √©t√© propos√©s. Dans les exp√©riences du chapitre¬†<a href="#chap2" data-reference-type="ref" data-reference="chap2">[chap2]</a>, on utilise l‚Äôalgorithme C4.5¬†<a href="#quinlan2014c4" class="citation" data-cites="quinlan2014c4">[4]</a> qui repose sur la divergence de Kullback-Leibler pour choisir une variable <span class="math inline"><em>x</em><sub><em>j</em></sub></span> √† chaque noeud et un ensemble <span class="math inline"><em>C</em><sub><em>j</em></sub></span> tel que les observations v√©rifiant <span class="math inline"><em>x</em><sub><em>j</em></sub>‚ÄÑ‚àà‚ÄÑ<em>C</em><sub><em>j</em></sub></span> (resp.¬†<span class="math inline"><em>x</em><sub><em>j</em></sub>‚ÄÑ‚àâ‚ÄÑ<em>C</em><sub><em>j</em></sub></span>) soient orient√©es vers le noeud fils gauche (resp.¬†droit), o√π <span class="math inline"><em>C</em><sub><em>j</em></sub>‚ÄÑ=‚ÄÑ]‚ÄÖ‚àí‚ÄÖ‚àû;‚ÄÜ<em>c</em><sub><em>j</em></sub>]</span>, <span class="math inline">\(c_j \in \mathbb{R}\)</span> pour les variables continues et <span class="math inline">\(C_j \subset \mathbb{N}_{o_j}\)</span> pour les variables cat√©gorielles. L‚Äôalgorithme s‚Äôarr√™te lorsque les feuilles ne contiennent qu‚Äôune seule classe, et des techniques d‚Äô‚Äú√©lagage‚Äù permettent ensuite de r√©duire la complexit√© de l‚Äôarbre r√©sultant pour garantir un bon compromis biais-variance.</p>
                                        <h5 id="faiblesses">Faiblesses</h5>
                                        <p>Les arbres de d√©cision souffrent souvent de large variance¬†<a href="#geurts2000investigation" class="citation" data-cites="geurts2000investigation">[3]</a>. C‚Äôest pourquoi, les For√™ts Al√©atoires¬†<a href="#breiman2001random" class="citation" data-cites="breiman2001random">[2]</a> et / ou algorithmes dits de ‚ÄúBoosting‚Äù¬†<a href="#zhou2012ensemble" class="citation" data-cites="zhou2012ensemble">[1]</a> sont pl√©biscit√©s¬†: plusieurs arbres de d√©cision sont appris, sur des sous-√©chantillons et / ou en pond√©rant les observations d‚Äôapprentissage, dont les d√©cisions sont ensuite combin√©es. Pour les donn√©es de <em>Credit Scoring</em>, il a √©t√© constat√© en interne √† <span data-acronym-label="cacf" data-acronym-form="singular+short">CACF</span> que ces mod√®les permettent d‚Äôobtenir de bonnes performances, en perdant cependant l‚Äôinterpr√©tation ais√©e des arbres de d√©cision ou de la r√©gression logistique.</p>
                                        <h4 id="r√©seaux-de-neurones">R√©seaux de neurones</h4>
                                        <h5 id="principe-1">Principe</h5>
                                        <p>Chaque variable d‚Äôentr√©e, c‚Äôest-√†-dire une covariable <span class="math inline">\(\boldsymbol{x}_j\)</span>, est vue comme un neurone, tout comme la variable de sortie, c‚Äôest-√†-dire la variable d√©pendante √† pr√©dire <span class="math inline"><em>y</em></span>. Les neurones interm√©diaires, formant la (les) couche(s) cach√©e(s) r√©alisent un calcul √† partir de leur(s) neurone(s) parent(s) (phase de propagation dite <em>feedforward</em>) consistant typiquement en une addition et une transformation non-lin√©aire (comme la fonction sigmo√Øde - l‚Äôapplication r√©ciproque du logit - qui sert en r√©gression logistique). Les r√©sultats pr√©dits <span class="math inline">\(\hat{\boldsymbol{\mathbf{y}}}\)</span> sont compar√©s aux exemples d‚Äôapprentissage <span class="math inline">\(\boldsymbol{\mathbf{y}}\)</span> et l‚Äôerreur est r√©tropropag√©e (phase dite <em>backpropagation</em>) : comme en r√©gression logistique, les couches cach√©es disposent de coefficients <span class="math inline">\(\boldsymbol{\theta}\)</span> qui sont ajust√©s par descente de gradient. La comparaison biologique est cependant bien plus limit√©e que ce que leur nom laisse supposer : les neurones repr√©sentent simplement un √©tat r√©sultant d‚Äôun calcul, et les synapses sont les ar√™tes du graphe de calcul (qui d√©terminent le(s) neurone(s) parent(s) / enfant(s) de chaque neurone).</p>
                                        <h5 id="limites-et-d√©veloppements-r√©cents">Limites et d√©veloppements r√©cents</h5>
                                        <p>Les inconv√©nients de ce type de mod√®le vont de paire avec leur avantage de flexibilit√© : le grand nombre de param√®tres et hyperparam√®tres rendent leur interpr√©tation et leur apprentissage compliqu√©s. L‚Äôinterpr√©tation ais√©e du mod√®le, <em>e.g.</em> de l‚Äôeffet de chaque variable (et de la significativit√© de cet effet), de la forme de la fronti√®re de d√©cision, est primordial dans de nombreux contextes applicatifs comme le <em>Credit Scoring</em> : le management, dont l‚Äôexposition aux statistiques est faible ou nulle, doit pouvoir comprendre le processus de d√©cision de m√™me que le client pouvant se voir refuser l‚Äôacc√®s au cr√©dit. C‚Äôest pourquoi les r√©gulateurs bancaires sont attentifs √† ce que les d√©cisions soient explicables au client, ce qui est g√©n√©ralement garanti par l‚Äôusage massif de la r√©gression logistique, mod√®le d√©velopp√© dans les parties pr√©c√©dentes, mais qui est moins imm√©diat dans le cas pr√©sent des r√©seaux de neurones du fait de l‚Äôintroduction de nombreuses non-lin√©arit√©s et combinaisons de plusieurs variables (toutes les variables dans le cas des r√©seaux dits dens√©ment connect√©s). Par ailleurs, ces mod√®les reposent sur des techniques de descente de gradient, bri√®vement √©voqu√©s en partie¬†<a href="#subsec:gradient" data-reference-type="ref" data-reference="subsec:gradient">1.3.2</a>, qui demandent des connaissances <em>ad hoc</em> et / ou sp√©cifiques au domaine d‚Äôapplication pour la calibration des nombreux hyperparam√®tres entre autres li√©s au pas de gradient.</p>
                                        <p>Le lecteur d√©sireux d‚Äôapprofondir sa connaissance sur ce type de mod√®le, devenu une discipline de recherche √† part enti√®re, peut se r√©f√©rer √† l‚Äôouvrage¬†¬†<a href="#goodfellow2016deep" class="citation" data-cites="goodfellow2016deep">[13]</a>.</p>
                                        
                                        <div id="HCB_comment_box"><a href="http://www.htmlcommentbox.com">Comment Box</a> is loading comments...</div>
                                        <link rel="stylesheet" type="text/css" href="//www.htmlcommentbox.com/static/skins/bootstrap/twitter-bootstrap.css?v=0" />
                                        <script type="text/javascript" id="hcb"> /*<!--*/ if(!window.hcb_user){hcb_user={};} (function(){var s=document.createElement("script"), l=hcb_user.PAGE || (""+window.location).replace(/'/g,"%27"), h="//www.htmlcommentbox.com";s.setAttribute("type","text/javascript");s.setAttribute("src", h+"/jread?page="+encodeURIComponent(l).replace("+","%2B")+"&mod=%241%24wq1rdBcg%247122Rf3pq5RdU5hlkjJ4L1"+"&opts=16862&num=50&ts=1486459652719");if (typeof s!="undefined") document.getElementsByTagName("head")[0].appendChild(s);})(); /*-->*/ </script>
                                        <!-- end www.htmlcommentbox.com -->
                                        </div>

                                        
                                        <br></br>
                                        <h4>R√©f√©rences</h4>
                                        <table>
                                            
                                            <tr valign="top">
                                                <td align="right" class="bibtexnumber">
                                                    [<a name="zhou2012ensemble">1</a>]
                                                </td>
                                                <td class="bibtexitem">
                                                    Zhi-Hua Zhou.
                                                    <em>Ensemble methods: foundations and algorithms</em>.
                                                    Chapman and Hall/CRC, 2012.
                                                    [&nbsp;<a href="chapitre1_bib.html#zhou2012ensemble">bib</a>&nbsp;]
                                                    
                                                </td>
                                            </tr>
                                            
                                            
                                            <tr valign="top">
                                                <td align="right" class="bibtexnumber">
                                                    [<a name="breiman2001random">2</a>]
                                                </td>
                                                <td class="bibtexitem">
                                                    Leo Breiman.
                                                    Random forests.
                                                    <em>Machine learning</em>, 45(1):5-32, 2001.
                                                    [&nbsp;<a href="chapitre1_bib.html#breiman2001random">bib</a>&nbsp;]
                                                    
                                                </td>
                                            </tr>
                                            
                                            
                                            <tr valign="top">
                                                <td align="right" class="bibtexnumber">
                                                    [<a name="geurts2000investigation">3</a>]
                                                </td>
                                                <td class="bibtexitem">
                                                    Pierre Geurts and Louis Wehenkel.
                                                    Investigation and reduction of discretization variance in decision
                                                    tree induction.
                                                    In <em>European Conference on Machine Learning</em>, pages 162-170.
                                                    Springer, 2000.
                                                    [&nbsp;<a href="chapitre1_bib.html#geurts2000investigation">bib</a>&nbsp;]
                                                    
                                                </td>
                                            </tr>
                                            
                                            
                                            <tr valign="top">
                                                <td align="right" class="bibtexnumber">
                                                    [<a name="quinlan2014c4">4</a>]
                                                </td>
                                                <td class="bibtexitem">
                                                    J&nbsp;Ross Quinlan.
                                                    <em>C4. 5: programs for machine learning</em>.
                                                    Elsevier, 2014.
                                                    [&nbsp;<a href="chapitre1_bib.html#quinlan2014c4">bib</a>&nbsp;]
                                                    
                                                </td>
                                            </tr>
                                            
                                            
                                            <tr valign="top">
                                                <td align="right" class="bibtexnumber">
                                                    [<a name="scholkopf2002learning">5</a>]
                                                </td>
                                                <td class="bibtexitem">
                                                    Bernhard Sch&ouml;lkopf, Alexander&nbsp;J Smola, Francis Bach, et&nbsp;al.
                                                    <em>Learning with kernels: support vector machines, regularization,
                                                        optimization, and beyond</em>.
                                                    MIT press, 2002.
                                                    [&nbsp;<a href="chapitre1_bib.html#scholkopf2002learning">bib</a>&nbsp;]
                                                    
                                                </td>
                                            </tr>
                                            
                                            
                                            <tr valign="top">
                                                <td align="right" class="bibtexnumber">
                                                    [<a name="BIC">6</a>]
                                                </td>
                                                <td class="bibtexitem">
                                                    Gideon Schwarz.
                                                    Estimating the dimension of a model.
                                                    <em>The Annals of Statistics</em>, 6(2):461-464, 1978.
                                                    [&nbsp;<a href="chapitre1_bib.html#BIC">bib</a>&nbsp;|
                                                    <a href="http://www.jstor.org/stable/2958889">http</a>&nbsp;]
                                                    <blockquote><font size="-1">
                                                        The problem of selecting one of a number of models of different dimensions is treated by finding its Bayes solution, and evaluating the leading terms of its asymptotic expansion. These terms are a valid large-sample criterion beyond the Bayesian context, since they do not depend on the a priori distribution.
                                                    </font></blockquote>
                                                    <p>
                                                </td>
                                            </tr>
                                            
                                            
                                            <tr valign="top">
                                                <td align="right" class="bibtexnumber">
                                                    [<a name="white1982maximum">7</a>]
                                                </td>
                                                <td class="bibtexitem">
                                                    Halbert White.
                                                    Maximum likelihood estimation of misspecified models.
                                                    <em>Econometrica: Journal of the Econometric Society</em>, pages 1-25,
                                                    1982.
                                                    [&nbsp;<a href="chapitre1_bib.html#white1982maximum">bib</a>&nbsp;]
                                                    
                                                </td>
                                            </tr>
                                            
                                            
                                            <tr valign="top">
                                                <td align="right" class="bibtexnumber">
                                                    [<a name="schutze2008introduction">8</a>]
                                                </td>
                                                <td class="bibtexitem">
                                                    Hinrich Sch&uuml;tze, Christopher&nbsp;D Manning, and Prabhakar Raghavan.
                                                    <em>Introduction to information retrieval</em>, volume&nbsp;39.
                                                    Cambridge University Press, 2008.
                                                    [&nbsp;<a href="chapitre1_bib.html#schutze2008introduction">bib</a>&nbsp;|
                                                    <a href="https://nlp.stanford.edu/IR-book/pdf/irbookprint.pdf">.pdf</a>&nbsp;]
                                                    
                                                </td>
                                            </tr>
                                            
                                            
                                            <tr valign="top">
                                                <td align="right" class="bibtexnumber">
                                                    [<a name="vital2016">9</a>]
                                                </td>
                                                <td class="bibtexitem">
                                                    Cl√©ment Vital.
                                                    <em>Scoring pour le risque de cr√©dit : variable r√©ponse
                                                        polytomique, s√©lection de variables, r√©duction de la dimension,
                                                        applications</em>.
                                                    PhD thesis, 2016.
                                                    Th√®se de doctorat dirig√©e par Patilea, Valentin et Rouviere,
                                                    Laurent Math√©matiques et applications Rennes 1 2016.
                                                    [&nbsp;<a href="chapitre1_bib.html#vital2016">bib</a>&nbsp;|
                                                    <a href="http://www.theses.fr/2016REN1S111">http</a>&nbsp;]
                                                    
                                                </td>
                                            </tr>
                                            
                                            
                                            <tr valign="top">
                                                <td align="right" class="bibtexnumber">
                                                    [<a name="byrd1995limited">10</a>]
                                                </td>
                                                <td class="bibtexitem">
                                                    Richard&nbsp;H Byrd, Peihuang Lu, Jorge Nocedal, and Ciyou Zhu.
                                                    A limited memory algorithm for bound constrained optimization.
                                                    <em>SIAM Journal on Scientific Computing</em>, 16(5):1190-1208, 1995.
                                                    [&nbsp;<a href="chapitre1_bib.html#byrd1995limited">bib</a>&nbsp;]
                                                    
                                                </td>
                                            </tr>
                                            
                                            
                                            <tr valign="top">
                                                <td align="right" class="bibtexnumber">
                                                    [<a name="minka2003comparison">11</a>]
                                                </td>
                                                <td class="bibtexitem">
                                                    Thomas&nbsp;P Minka.
                                                    A comparison of numerical optimizers for logistic regression.
                                                    <em>Unpublished draft</em>, pages 1-18, 2003.
                                                    [&nbsp;<a href="chapitre1_bib.html#minka2003comparison">bib</a>&nbsp;]
                                                    
                                                </td>
                                            </tr>
                                            
                                            
                                            <tr valign="top">
                                                <td align="right" class="bibtexnumber">
                                                    [<a name="vapnik2013nature">12</a>]
                                                </td>
                                                <td class="bibtexitem">
                                                    Vladimir Vapnik.
                                                    <em>The nature of statistical learning theory</em>.
                                                    Springer science &amp; business media, 2013.
                                                    [&nbsp;<a href="chapitre1_bib.html#vapnik2013nature">bib</a>&nbsp;]
                                                    
                                                </td>
                                            </tr>
                                            
                                            
                                            <tr valign="top">
                                                <td align="right" class="bibtexnumber">
                                                    [<a name="goodfellow2016deep">13</a>]
                                                </td>
                                                <td class="bibtexitem">
                                                    Ian Goodfellow, Yoshua Bengio, Aaron Courville, and Yoshua Bengio.
                                                    <em>Deep Learning</em>, volume&nbsp;1.
                                                    MIT press Cambridge, 2016.
                                                    [&nbsp;<a href="chapitre1_bib.html#goodfellow2016deep">bib</a>&nbsp;]
                                                    
                                                </td>
                                            </tr>
                                            
                                            
                                            <tr valign="top">
                                                <td align="right" class="bibtexnumber">
                                                    [<a name="cortes2005confidence">14</a>]
                                                </td>
                                                <td class="bibtexitem">
                                                    Corinna Cortes and Mehryar Mohri.
                                                    Confidence intervals for the area under the roc curve.
                                                    In <em>Advances in neural information processing systems</em>, pages
                                                    305-312, 2005.
                                                    [&nbsp;<a href="chapitre1_bib.html#cortes2005confidence">bib</a>&nbsp;]
                                                    
                                                </td>
                                            </tr>
                                            
                                            
                                            <tr valign="top">
                                                <td align="right" class="bibtexnumber">
                                                    [<a name="sun2014fast">15</a>]
                                                </td>
                                                <td class="bibtexitem">
                                                    Xu&nbsp;Sun and Weichao Xu.
                                                    Fast implementation of delong's algorithm for comparing the areas
                                                    under correlated receiver oerating characteristic curves.
                                                    <em>IEEE Signal Processing Letters</em>, 21(11):1389-1393, 2014.
                                                    [&nbsp;<a href="chapitre1_bib.html#sun2014fast">bib</a>&nbsp;]
                                                    
                                                </td>
                                            </tr>
                                            
                                            
                                            <tr valign="top">
                                                <td align="right" class="bibtexnumber">
                                                    [<a name="sun2009classification">16</a>]
                                                </td>
                                                <td class="bibtexitem">
                                                    Yanmin Sun, Andrew&nbsp;KC Wong, and Mohamed&nbsp;S Kamel.
                                                    Classification of imbalanced data: A review.
                                                    <em>International Journal of Pattern Recognition and Artificial
                                                        Intelligence</em>, 23(04):687-719, 2009.
                                                    [&nbsp;<a href="chapitre1_bib.html#sun2009classification">bib</a>&nbsp;]
                                                    
                                                </td>
                                            </tr>
                                            
                                            
                                            <tr valign="top">
                                                <td align="right" class="bibtexnumber">
                                                    [<a name="baesens2003benchmarking">17</a>]
                                                </td>
                                                <td class="bibtexitem">
                                                    Bart Baesens, Tony Van&nbsp;Gestel, Stijn Viaene, Maria Stepanova, Johan Suykens,
                                                    and Jan Vanthienen.
                                                    Benchmarking state-of-the-art classification algorithms for credit
                                                    scoring.
                                                    <em>Journal of the operational research society</em>, 54(6):627-635,
                                                    2003.
                                                    [&nbsp;<a href="chapitre1_bib.html#baesens2003benchmarking">bib</a>&nbsp;]
                                                    
                                                </td>
                                            </tr>
                                            
                                            
                                            <tr valign="top">
                                                <td align="right" class="bibtexnumber">
                                                    [<a name="brown2012experimental">18</a>]
                                                </td>
                                                <td class="bibtexitem">
                                                    Iain Brown and Christophe Mues.
                                                    An experimental comparison of classification algorithms for
                                                    imbalanced credit scoring data sets.
                                                    <em>Expert Systems with Applications</em>, 39(3):3446-3453, 2012.
                                                    [&nbsp;<a href="chapitre1_bib.html#brown2012experimental">bib</a>&nbsp;]
                                                    
                                                </td>
                                            </tr>
                                            
                                            
                                            <tr valign="top">
                                                <td align="right" class="bibtexnumber">
                                                    [<a name="kullback1951information">19</a>]
                                                </td>
                                                <td class="bibtexitem">
                                                    Solomon Kullback and Richard&nbsp;A Leibler.
                                                    On information and sufficiency.
                                                    <em>The annals of mathematical statistics</em>, 22(1):79-86, 1951.
                                                    [&nbsp;<a href="chapitre1_bib.html#kullback1951information">bib</a>&nbsp;]
                                                    
                                                </td>
                                            </tr>
                                            
                                            
                                            <tr valign="top">
                                                <td align="right" class="bibtexnumber">
                                                    [<a name="thomas2000survey">20</a>]
                                                </td>
                                                <td class="bibtexitem">
                                                    Lyn&nbsp;C Thomas.
                                                    A survey of credit and behavioural scoring: forecasting financial
                                                    risk of lending to consumers.
                                                    <em>International journal of forecasting</em>, 16(2):149-172, 2000.
                                                    [&nbsp;<a href="chapitre1_bib.html#thomas2000survey">bib</a>&nbsp;]
                                                    
                                                </td>
                                            </tr>
                                            
                                            
                                            <tr valign="top">
                                                <td align="right" class="bibtexnumber">
                                                    [<a name="finlay2010credit">21</a>]
                                                </td>
                                                <td class="bibtexitem">
                                                    Steven Finlay.
                                                    Credit scoring for profitability objectives.
                                                    <em>European Journal of Operational Research</em>, 202(2):528-537,
                                                    2010.
                                                    [&nbsp;<a href="chapitre1_bib.html#finlay2010credit">bib</a>&nbsp;]
                                                    
                                                </td>
                                            </tr>
                                            
                                            
                                            <tr valign="top">
                                                <td align="right" class="bibtexnumber">
                                                    [<a name="finlay2009we">22</a>]
                                                </td>
                                                <td class="bibtexitem">
                                                    Steven Finlay.
                                                    Are we modelling the right thing? the impact of incorrect problem
                                                    specification in credit scoring.
                                                    <em>Expert Systems with Applications</em>, 36(5):9065-9071, 2009.
                                                    [&nbsp;<a href="chapitre1_bib.html#finlay2009we">bib</a>&nbsp;]
                                                    
                                                </td>
                                            </tr>
                                            
                                            
                                            <tr valign="top">
                                                <td align="right" class="bibtexnumber">
                                                    [<a name="hand1997statistical">23</a>]
                                                </td>
                                                <td class="bibtexitem">
                                                    David&nbsp;J Hand and William&nbsp;E Henley.
                                                    Statistical classification methods in consumer credit scoring: a
                                                    review.
                                                    <em>Journal of the Royal Statistical Society: Series A (Statistics
                                                        in Society)</em>, 160(3):523-541, 1997.
                                                    [&nbsp;<a href="chapitre1_bib.html#hand1997statistical">bib</a>&nbsp;]
                                                    
                                                </td>
                                            </tr>
                                            
                                            
                                            <tr valign="top">
                                                <td align="right" class="bibtexnumber">
                                                    [<a name="friedman2001elements">24</a>]
                                                </td>
                                                <td class="bibtexitem">
                                                    Jerome Friedman, Trevor Hastie, and Robert Tibshirani.
                                                    <em>The Elements of Statistical Learning</em>, volume&nbsp;1.
                                                    Springer series in statistics New York, NY, USA:, 2001.
                                                    [&nbsp;<a href="chapitre1_bib.html#friedman2001elements">bib</a>&nbsp;]
                                                    
                                                </td>
                                            </tr>
                                            
                                            
                                            <tr valign="top">
                                                <td align="right" class="bibtexnumber">
                                                    [<a name="ducourant2009credit">25</a>]
                                                </td>
                                                <td class="bibtexitem">
                                                    H&eacute;l&egrave;ne Ducourant.
                                                    Le cr&eacute;dit revolving, un succ&egrave;s populaire.
                                                    <em>Soci&eacute;t&eacute;s contemporaines</em>, (4):41-65, 2009.
                                                    [&nbsp;<a href="chapitre1_bib.html#ducourant2009credit">bib</a>&nbsp;]
                                                    
                                                </td>
                                            </tr>
                                            
                                            
                                            <tr valign="top">
                                                <td align="right" class="bibtexnumber">
                                                    [<a name="credit_cards_country">26</a>]
                                                </td>
                                                <td class="bibtexitem">
                                                    Statista.
                                                    Credit cards per household by country in 2016, 2016.
                                                    [&nbsp;<a href="chapitre1_bib.html#credit_cards_country">bib</a>&nbsp;|
                                                    <a href="https://www.statista.com/statistics/650858/credit-cards-per-household-by-country/">http</a>&nbsp;]
                                                    
                                                </td>
                                            </tr>
                                            
                                            
                                            <tr valign="top">
                                                <td align="right" class="bibtexnumber">
                                                    [<a name="dicharry_2017">27</a>]
                                                </td>
                                                <td class="bibtexitem">
                                                    Elsa Dicharry.
                                                    Maison de la literie lance la location avec option d'achat, 10 2017.
                                                    [&nbsp;<a href="chapitre1_bib.html#dicharry_2017">bib</a>&nbsp;|
                                                    <a href="https://www.lesechos.fr/26/10/2017/lesechos.fr/030786701376_maison-de-la-literie-lance-la-location-avec-option-d-achat.htm">http</a>&nbsp;]
                                                    
                                                </td>
                                            </tr>
                                            
                                            
                                            <tr valign="top">
                                                <td align="right" class="bibtexnumber">
                                                    [<a name="peden_2018">28</a>]
                                                </td>
                                                <td class="bibtexitem">
                                                    Jean-Philippe Peden.
                                                    Vente de voitures : la part des formules de location a d√©coll√© en
                                                    2017, 01 2018.
                                                    [&nbsp;<a href="chapitre1_bib.html#peden_2018">bib</a>&nbsp;|
                                                    <a href="https://news.autoplus.fr/Location-LLD-LOA-Vente-Marques-premium-1523494.html">.html</a>&nbsp;]
                                                    
                                                </td>
                                            </tr>
                                            
                                            
                                            <tr valign="top">
                                                <td align="right" class="bibtexnumber">
                                                    [<a name="karim2013off">29</a>]
                                                </td>
                                                <td class="bibtexitem">
                                                    Dilruba Karim, Iana Liadze, Ray Barrell, and E&nbsp;Philip Davis.
                                                    Off-balance sheet exposures and banking crises in oecd countries.
                                                    <em>Journal of Financial Stability</em>, 9(4):673-681, 2013.
                                                    [&nbsp;<a href="chapitre1_bib.html#karim2013off">bib</a>&nbsp;]
                                                    
                                                </td>
                                            </tr>
                                        </table>



								</div>
							</section>

							<section id="footer">
						<div class="container">
							<ul class="copyright">
								<li>&copy; Adrien Ehrhardt. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</section>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollzer.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>

	</body>
</html>
